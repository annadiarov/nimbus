{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Model from repo:\n",
    "\n",
    "https://github.com/lucidrains/bidirectional-cross-attention"
   ],
   "id": "bf466e5efd5d76f1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Adapt function to work with our data\n",
    "\n",
    "We will use:\n",
    "> For peptide the csv file with the peptide sequences, hla, and label\n",
    "\n",
    "> For HLA the raw data with the hla fingerprints"
   ],
   "id": "c3816c8d60a45851"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:28:07.851902Z",
     "start_time": "2024-05-19T21:28:07.848333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch import einsum\n",
    "import torchmetrics\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import logging\n",
    "from logavgexp_pytorch import logavgexp\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from bidirectional_cross_attention import BidirectionalCrossAttention\n"
   ],
   "id": "6142116647ba7142",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:02:33.840502Z",
     "start_time": "2024-05-19T14:02:33.836072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def balance_data(data: np.array or pd.DataFrame,\n",
    "                 binary_labels: np.array or pd.Series, \n",
    "                 random_seed: int = 42):\n",
    "    \"\"\"\n",
    "    Balance data by getting reducing the number of samples of the\n",
    "     majority class to the number of samples of the minority class\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "    # Balance data\n",
    "    pos_idx = np.where(binary_labels == 1)[0]\n",
    "    neg_idx = np.where(binary_labels == 0)[0]\n",
    "    \n",
    "    n_pos = len(pos_idx)\n",
    "    n_neg = len(neg_idx)\n",
    "    \n",
    "    n_samples = min(n_pos, n_neg)\n",
    "    \n",
    "    print(f\"There are {n_pos} positive samples and {n_neg} negative samples. \"\n",
    "          f\"We will balance the data to {n_samples} samples per class.\")\n",
    "    \n",
    "    pos_idx = np.random.choice(pos_idx, n_samples, replace=False)\n",
    "    neg_idx = np.random.choice(neg_idx, n_samples, replace=False)\n",
    "    \n",
    "    if type(data) == pd.DataFrame:\n",
    "        balanced_data = pd.concat([data.iloc[pos_idx], data.iloc[neg_idx]])\n",
    "    elif type(data) == np.array:\n",
    "        balanced_data = np.concatenate([data[pos_idx], data[neg_idx]])\n",
    "    else:\n",
    "        raise TypeError(\"Data must be a pandas DataFrame or a numpy array\")\n",
    "    \n",
    "    if type(binary_labels) == pd.Series:\n",
    "        balanced_labels = pd.concat([binary_labels.iloc[pos_idx], binary_labels.iloc[neg_idx]])\n",
    "    elif type(binary_labels) == np.array:\n",
    "        balanced_labels = np.concatenate([binary_labels[pos_idx], binary_labels[neg_idx]])\n",
    "    else:\n",
    "        raise TypeError(\"Data must be a pandas Series or a numpy array\")\n",
    "    \n",
    "    assert len(balanced_data) == len(balanced_labels), \"Data and labels do not have the same length. Check the code.\"\n",
    "    \n",
    "    return balanced_data, balanced_labels"
   ],
   "id": "16582d4ee8115ed8",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:02:33.862709Z",
     "start_time": "2024-05-19T14:02:33.841332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_PEPTIDE_LEN = 15\n",
    "BALANCE_DATA = True\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DATA_FOLDER = os.path.join('..', 'data')\n",
    "PROCESS_DATA_FOLDER = os.path.join(DATA_FOLDER, 'processed')\n",
    "PROCESS_pHLA_BINDING_DATA_FOLDER = os.path.join(PROCESS_DATA_FOLDER, 'pHLA_binding')\n",
    "PROCESS_pHLA_BINDING_NetMHDpan_FOLDER = os.path.join(PROCESS_pHLA_BINDING_DATA_FOLDER, 'NetMHCpan_dataset')\n",
    "PROCESS_HLA_FP_FOLDER = os.path.join(PROCESS_DATA_FOLDER, 'hla_fingerprints')\n",
    "\n",
    "# Just using MonoAllelicData\n",
    "train_peptide_ba_data_file = os.path.join(PROCESS_pHLA_BINDING_NetMHDpan_FOLDER, 'train_binding_affinity_peptides_data_MaxLenPep15_hla_ABC.csv')\n",
    "train_peptide_el_data_file = os.path.join(PROCESS_pHLA_BINDING_NetMHDpan_FOLDER, 'train_eluted_ligand_peptides_data_mono_MaxLenPep15_hla_ABC.csv.gz')\n",
    "test_peptide_data_file = os.path.join(PROCESS_pHLA_BINDING_NetMHDpan_FOLDER, 'test_set_peptides_data_MaxLenPep15_hla_ABC.csv.gz')\n",
    "hla_fp_data_file = os.path.join(PROCESS_HLA_FP_FOLDER, 'hla_fingerprint_netMHCpan_pseudoseq_res_representation.npy')\n",
    "hla_info_file = os.path.join(PROCESS_HLA_FP_FOLDER, 'hla_index_netMHCpan_pseudoseq_res_representation.csv')"
   ],
   "id": "e3a9c65c39d30361",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:02:33.912319Z",
     "start_time": "2024-05-19T14:02:33.904936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hla_data = np.load(hla_fp_data_file)\n",
    "hla_info = pd.read_csv(hla_info_file, index_col=0)\n",
    "# make a dict with hla names and their fingerprints using index\n",
    "hla_fp_dict = {hla_info.loc[i, 'hla_allele']: hla_data[i] for i in range(hla_data.shape[0])}"
   ],
   "id": "4f2bb40569d24af4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:02:42.925324Z",
     "start_time": "2024-05-19T14:02:34.375226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Make a list of HLA and a list of peptide sequences\n",
    "train_peptide_ba_data = pd.read_csv(train_peptide_ba_data_file)\n",
    "# train_peptide_el_data = pd.read_csv(train_peptide_el_data_file)\n",
    "test_peptide_data = pd.read_csv(test_peptide_data_file)\n",
    "\n",
    "if BALANCE_DATA:\n",
    "    train_peptide_ba_data, _ = balance_data(train_peptide_ba_data, train_peptide_ba_data.label)\n",
    "    # train_peptide_el_data, _ = balance_data(train_peptide_el_data, train_peptide_el_data.label)\n",
    "    test_peptide_data, _ = balance_data(test_peptide_data, test_peptide_data.label)"
   ],
   "id": "3609a9e394810ab7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 42001 positive samples and 128106 negative samples. We will balance the data to 42001 samples per class.\n",
      "There are 1660 positive samples and 11770570 negative samples. We will balance the data to 1660 samples per class.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:02:42.930519Z",
     "start_time": "2024-05-19T14:02:42.926732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_hla_ba = train_peptide_ba_data.hla_allele.to_numpy()\n",
    "train_peptide_ba = train_peptide_ba_data.peptide.to_numpy()\n",
    "train_labels_ba = train_peptide_ba_data.label.to_numpy()\n",
    "\n",
    "# train_hla_el = train_peptide_el_data.hla_allele.to_numpy()\n",
    "# train_peptide_el = train_peptide_el_data.peptide.to_numpy()\n",
    "# train_labels_el = train_peptide_el_data.label.to_numpy()\n",
    "\n",
    "test_hla = test_peptide_data.hla_allele.to_numpy()\n",
    "test_peptide = test_peptide_data.peptide.to_numpy()\n",
    "test_labels = test_peptide_data.label.to_numpy()"
   ],
   "id": "c5c8703828628ee3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:02:42.953446Z",
     "start_time": "2024-05-19T14:02:42.931447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SeqTokenizer:\n",
    "    def __init__(self):\n",
    "        padding_chr = 'X'\n",
    "        alphabet = padding_chr + 'ACDEFGHIKLMNPQRSTVWY' \n",
    "        self.alphabet = alphabet\n",
    "        self.padding_chr = padding_chr\n",
    "        self.padding_idx = alphabet.index(padding_chr)\n",
    "        self.char2idx = {char: i for i, char in enumerate(alphabet)}\n",
    "        self.idx2char = {i: char for i, char in enumerate(alphabet)}\n",
    "    \n",
    "    def tokenize(self, seq):\n",
    "        return [self.char2idx[char] for char in seq]\n",
    "    \n",
    "    def detokenize(self, tokens):\n",
    "        return ''.join([self.idx2char[i] for i in tokens])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.alphabet)\n",
    "\n",
    "class pHLAData(torch.utils.data.Dataset):\n",
    "    def __init__(self, peptide_seq_arr, hla_names_arr, hla_fp_dict, labels, pep_tokenizer, max_peptide_len=15):\n",
    "        # Validate inputs\n",
    "        assert len(peptide_seq_arr) == len(hla_names_arr) == len(labels),\\\n",
    "            'Peptide, HLA and labels must have the same length'\n",
    "        assert type(peptide_seq_arr) == np.ndarray, 'peptide_seq_arr must be a numpy array'\n",
    "        assert type(hla_names_arr) == np.ndarray, 'hla_names_arr must be a numpy array'\n",
    "        assert type(labels) == np.ndarray, 'labels must be a numpy array'\n",
    "        hla_keys = set(list(hla_fp_dict))\n",
    "        unique_hla_list = set(hla_names_arr)\n",
    "        if not unique_hla_list.issubset(hla_keys):\n",
    "            err_msg = (f\"hla_fp_dict does not have all the hla_names.\"\n",
    "                       f\" Missing HLAs: {unique_hla_list - hla_keys}\")\n",
    "            raise KeyError(err_msg)\n",
    "        \n",
    "        peptide_pad = [pep + 'X'*(max_peptide_len-len(pep)) for pep in peptide_seq_arr]\n",
    "        peptide_idx_list = [torch.Tensor(pep_tokenizer.tokenize(pep)).long() for pep in peptide_pad]\n",
    "        self.peptides = peptide_idx_list\n",
    "        hlas_fp_list = [torch.Tensor(hla_fp_dict[hla]) for hla in hla_names_arr]\n",
    "        self.hlas = hlas_fp_list # In the same order as peptide\n",
    "        # one hot encoding of labels\n",
    "        N_LABELS = 2 # binary classification\n",
    "        labels = np.eye(N_LABELS)[labels]\n",
    "        self.labels = torch.Tensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.hlas)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        hla_fp = self.hlas[idx]\n",
    "        peptide_idx = self.peptides[idx]\n",
    "        label = self.labels[idx]\n",
    "        return peptide_idx, hla_fp, label \n",
    "    "
   ],
   "id": "3f6a6ad83d6baf79",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:02:42.970553Z",
     "start_time": "2024-05-19T14:02:42.954777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tensor helpers\n",
    "def l2norm(t):\n",
    "    return F.normalize(t, dim = -1)\n",
    "\n",
    "def prob_mask_like(t, prob):\n",
    "    return torch.zeros_like(t).float().uniform_(0, 1) < prob\n",
    "\n",
    "def fourier_encode(x, dims, theta = 20000):\n",
    "    device, dtype = x.device, x.dtype\n",
    "    emb = math.log(theta) / (dims // 2)\n",
    "    emb = torch.exp(torch.arange(dims // 2, device = device) * -emb)\n",
    "    emb = rearrange(x, 'n -> n 1') * rearrange(emb, 'd -> 1 d')\n",
    "    emb = torch.cat((emb.sin(), emb.cos()), dim = -1)\n",
    "    return emb\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def FeedForward(dim, mult = 4, dropout = 0.):\n",
    "    return nn.Sequential(\n",
    "        nn.LayerNorm(dim),\n",
    "        nn.Linear(dim, dim * mult),\n",
    "        nn.GELU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(dim * mult, dim)\n",
    "    )\n",
    "\n",
    "# read value MLP for calculating auxiliary loss\n",
    "class ReadValueMLP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        *,\n",
    "        fourier_dims = 256,\n",
    "        norm_factor_fourier = 50,\n",
    "        norm_factor_linear = 8000,\n",
    "        eps = 1e-20\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.fourier_dims = fourier_dims\n",
    "        self.norm_factor_fourier = norm_factor_fourier\n",
    "        self.norm_factor_linear = norm_factor_linear\n",
    "\n",
    "        self.logits_norm = nn.Sequential(\n",
    "            Reduce('b n d -> b d', 'mean'),\n",
    "            nn.LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim + fourier_dims + 2, dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(dim * 2, 1),\n",
    "            Rearrange('... 1 -> ...')\n",
    "        )\n",
    "\n",
    "    def forward(self, logits, peaks_nr, read_value):\n",
    "        logits = self.logits_norm(logits)\n",
    "\n",
    "        peaks_nr_log_space = torch.log(peaks_nr + self.eps)\n",
    "\n",
    "        peaks_nr = rearrange(peaks_nr, '... -> (...)')\n",
    "        peaks_nr_encoded = fourier_encode(peaks_nr / self.norm_factor_fourier, self.fourier_dims)\n",
    "        peaks_nr_normed = rearrange(peaks_nr, '... -> ... 1') / self.norm_factor_linear\n",
    "\n",
    "        peaks_nr_encoded_with_self = torch.cat((peaks_nr_normed, peaks_nr_log_space, peaks_nr_encoded), dim = -1)\n",
    "\n",
    "        logits_with_peaks = torch.cat((logits, peaks_nr_encoded_with_self), dim = -1)\n",
    "\n",
    "        pred = self.mlp(logits_with_peaks)\n",
    "        read_value = rearrange(read_value, '... -> (...)')\n",
    "\n",
    "        return F.smooth_l1_loss(pred, read_value)\n",
    "\n",
    "class HypergridLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        dim_out,\n",
    "        *,\n",
    "        context_dim\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.weights = nn.Parameter(torch.randn(dim, dim_out))\n",
    "        self.contextual_projection = nn.Linear(context_dim, dim * dim_out)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        # derive contextual gating, from hypergrids paper\n",
    "\n",
    "        gating = self.contextual_projection(context).sigmoid()\n",
    "        gating = rearrange(gating, 'b (i o) -> b i o', i = int(math.sqrt(gating.shape[-1])))\n",
    "\n",
    "        # gate interactions projection with context\n",
    "\n",
    "        to_logits_w = rearrange(self.weights, 'i o -> 1 i o') * gating\n",
    "        return einsum('b n d, b d e -> b n e', x, to_logits_w)\n",
    "\n",
    "\n",
    "class FILIP(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        context_dim,\n",
    "        heads,\n",
    "        dim_head = 64,\n",
    "        dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        inner_latent_dim = heads * dim_head\n",
    "\n",
    "        self.to_latent_w = nn.Parameter(torch.randn(dim, inner_latent_dim))\n",
    "        self.to_latent_b = nn.Parameter(torch.randn(inner_latent_dim))\n",
    "\n",
    "        self.pre_attn_dropout = dropout\n",
    "\n",
    "        self.null_context = nn.Parameter(torch.randn(heads, dim_head))\n",
    "        self.context_to_latent_w = nn.Parameter(torch.randn(context_dim, inner_latent_dim))\n",
    "        self.context_to_latent_b = nn.Parameter(torch.randn(inner_latent_dim))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        context,\n",
    "        context_mask = None\n",
    "    ):\n",
    "        b, heads, device = x.shape[0], self.heads, x.device\n",
    "\n",
    "        x = einsum('b n d, d e -> b n e', x, self.to_latent_w)\n",
    "        x = x + self.to_latent_b\n",
    "\n",
    "        x = rearrange(x, 'b n (h d) -> b h n d', h = heads)\n",
    "\n",
    "        context = einsum('b n d, d e -> b n e', context, self.context_to_latent_w)\n",
    "        context = context + self.context_to_latent_b\n",
    "\n",
    "        context = rearrange(context, 'b n (h d) -> b h n d', h = heads)\n",
    "\n",
    "        context, x = map(l2norm, (context, x))\n",
    "\n",
    "        # fine grained interaction between dna and protein sequences\n",
    "        # FILIP https://arxiv.org/abs/2111.07783\n",
    "\n",
    "        if x.shape[0] == 1:\n",
    "            # in the case one passes in 1 genomic sequence track\n",
    "            # but multiple factors + contexts, as in enformer training\n",
    "            x = rearrange(x, '1 ... -> ...')\n",
    "            einsum_eq = 'h i d, b h j d -> b h i j'\n",
    "        else:\n",
    "            einsum_eq = 'b h i d, b h j d -> b h i j'\n",
    "\n",
    "        # create context mask if not exist\n",
    "\n",
    "        if not exists(context_mask):\n",
    "            context_mask = torch.ones((b, context.shape[-1]), device = device).bool()\n",
    "\n",
    "        # dropout mask by dropout prob\n",
    "\n",
    "        if self.training:\n",
    "            keep_mask = prob_mask_like(context_mask, 1 - self.pre_attn_dropout)\n",
    "            context_mask = context_mask & keep_mask\n",
    "\n",
    "        # add null context and modify mask\n",
    "\n",
    "        context_mask = F.pad(context_mask, (1, 0), value = True)\n",
    "        context_mask = rearrange(context_mask, 'b j -> b 1 1 j')\n",
    "\n",
    "        null_context = repeat(self.null_context, 'h d -> b h 1 d', b = b)\n",
    "        context = torch.cat((null_context, context), dim = -2)\n",
    "\n",
    "        # differentiable max, as in FILIP paper\n",
    "\n",
    "        interactions = einsum(einsum_eq, x, context)\n",
    "        interactions = logavgexp(interactions, mask = context_mask, dim = -1, temp = 0.05)\n",
    "        interactions = rearrange(interactions, 'b h i -> b i h')\n",
    "        return interactions\n",
    "    \n"
   ],
   "id": "8c0eb3db08dd2d93",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:02:42.984088Z",
     "start_time": "2024-05-19T14:02:42.971502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PepHLAJointCrossAttentionBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 p_emb_dim=10,  # Number of features for each residue after the embedding\n",
    "                 hla_fp_dim=80, # Number of features for each residue fingerprint \n",
    "                 heads = 4,     # Num heads in Bidirectional Cross Attention\n",
    "                 dim_head = 64, # Dim of each head in Bidirectional Cross Attention\n",
    "                 ff_mult = 4,   # Dim multiplier in FeedForward after Bidirectional Cross Attention\n",
    "                 dropout = 0.):\n",
    "        \"\"\"\n",
    "        Higly inspired on JointCrossAttentionBlock from the repo:\n",
    "            https://github.com/lucidrains/tf-bind-transformer\n",
    "        \"\"\"\n",
    "        super(PepHLAJointCrossAttentionBlock, self).__init__()\n",
    "        self.joint_cross_attn = BidirectionalCrossAttention(\n",
    "            dim = p_emb_dim,\n",
    "            heads = heads,\n",
    "            dim_head = dim_head,\n",
    "            context_dim = hla_fp_dim\n",
    "        )\n",
    "        self.peptide_ff = FeedForward(p_emb_dim, mult = ff_mult, dropout = dropout)\n",
    "        self.hla_fp_ff = FeedForward(hla_fp_dim, mult = ff_mult, dropout = dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, pep_emb, hla_fp, peptide_mask, hla_fp_mask, return_attn = False):\n",
    "        cross_att_out = self.joint_cross_attn(\n",
    "            pep_emb,\n",
    "            hla_fp,\n",
    "            mask = peptide_mask,\n",
    "            context_mask = hla_fp_mask,\n",
    "            return_attn = return_attn\n",
    "        )\n",
    "        if return_attn:\n",
    "            pep_out, hla_out, pep_attn_out, hla_fp_attn_out = cross_att_out\n",
    "        else:\n",
    "            pep_out, hla_out = cross_att_out\n",
    "        pep_emb = pep_emb + pep_out\n",
    "        hla_fp = hla_fp + hla_out\n",
    "        \n",
    "        pep_emb = self.peptide_ff(pep_emb) + pep_emb\n",
    "        hla_fp = self.hla_fp_ff(hla_fp) + hla_fp\n",
    "        \n",
    "        return pep_emb, hla_fp"
   ],
   "id": "829cc4547015e71b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:15:48.604933Z",
     "start_time": "2024-05-19T14:15:48.598822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class pHLAPredictor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 p_emb_dim=10,  # Number of features for each residue after the embedding\n",
    "                 hla_fp_dim=80, # Number of features for each residue fingerprint \n",
    "                 joint_cross_attn_depth=1, # Number of JointCrossAttention blocks\n",
    "                 heads = 4,     # Num heads in Bidirectional Cross Attention\n",
    "                 dim_head = 64, # Dim of each head in Bidirectional Cross Attention\n",
    "                 ff_mult = 4,   # Dim multiplier in FeedForward after Bidirectional Cross Attention\n",
    "                 latent_heads = 4, # Num heads in FILIP\n",
    "                 latent_dim = 64,  # Dim of each head in FILIP\n",
    "                 condition_hypergrid = False, # If True, use HypergridLinear to condition the logits\n",
    "                 target_mse_loss = False, # If True, use MSE loss for the target\n",
    "                 fourier_dims = 256, # Dim of the Fourier encoding\n",
    "                 dropout = 0.,\n",
    "                 padding_idx_seq = 0):\n",
    "        \"\"\"\n",
    "        Highly inspired on AdapterModel from the repo:\n",
    "            https://github.com/lucidrains/tf-bind-transformer\n",
    "        \"\"\"\n",
    "        super(pHLAPredictor, self).__init__()\n",
    "        self.peptide_embedding = nn.Embedding(21, p_emb_dim, padding_idx=padding_idx_seq) # 20 AAs + 1 for padding\n",
    "        # joint attn\n",
    "        self.joint_cross_attns = nn.ModuleList([])\n",
    "        for _ in range(joint_cross_attn_depth):\n",
    "            attn = PepHLAJointCrossAttentionBlock(\n",
    "                        p_emb_dim=p_emb_dim,\n",
    "                        hla_fp_dim=hla_fp_dim,\n",
    "                        heads=heads,\n",
    "                        dim_head=dim_head,\n",
    "                        ff_mult=ff_mult,\n",
    "                        dropout=dropout)\n",
    "            self.joint_cross_attns.append(attn)\n",
    "\n",
    "        # latent space\n",
    "        self.filip = FILIP(\n",
    "            dim = p_emb_dim,\n",
    "            context_dim = hla_fp_dim,\n",
    "            heads = latent_heads,\n",
    "            dim_head = latent_dim,\n",
    "            dropout = dropout\n",
    "        )\n",
    "        \n",
    "        # hypergrid conditioning\n",
    "        if condition_hypergrid:\n",
    "            self.linear_with_hypergrid = HypergridLinear(latent_heads, latent_heads, context_dim = hla_fp_dim)\n",
    "        else:\n",
    "            self.linear_to_logits = nn.Linear(latent_heads, latent_heads)\n",
    "            self.linear_with_hypergrid = None\n",
    "            \n",
    "        \n",
    "        # Pred binary label\n",
    "            Rearrange('... 1 -> ...')\n",
    "        self.to_pred = nn.Sequential(\n",
    "            Reduce('... n d -> ... d', 'mean'),\n",
    "            nn.LayerNorm(latent_heads),\n",
    "            # nn.Linear(latent_heads, 1),\n",
    "            # Rearrange('... 1 -> ...')\n",
    "            nn.Linear(latent_heads, 2), # 2 classes\n",
    "        )\n",
    "\n",
    "        self.to_read_value_aux_loss = ReadValueMLP(\n",
    "            dim = latent_heads,\n",
    "            fourier_dims = fourier_dims\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, pep_seq_idx, hla_fp, peptide_mask, hla_fp_mask, return_attn = False):\n",
    "        pep_emb = self.peptide_embedding(pep_seq_idx)\n",
    "        for cross_attn in self.joint_cross_attns:\n",
    "            pep_emb, hla_fp = cross_attn(\n",
    "                pep_emb,\n",
    "                hla_fp,\n",
    "                peptide_mask = peptide_mask,\n",
    "                hla_fp_mask = hla_fp_mask,\n",
    "                return_attn = return_attn\n",
    "            )        \n",
    "        # project both embeddings into shared latent space\n",
    "        interactions = self.filip(\n",
    "            pep_emb,\n",
    "            hla_fp,\n",
    "            context_mask = hla_fp_mask\n",
    "        )\n",
    "\n",
    "        if exists(self.linear_with_hypergrid):\n",
    "            logits = self.linear_with_hypergrid(interactions, context = hla_fp_dim)\n",
    "        else:\n",
    "            logits = self.linear_to_logits(interactions)\n",
    "        pred = self.to_pred(logits)\n",
    "        pred = F.softmax(pred, dim=-1)\n",
    "        return pred"
   ],
   "id": "b163b4b9976b33fd",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testing it runs",
   "id": "9566f64174a87b8d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:08:21.099127Z",
     "start_time": "2024-05-19T14:08:19.902623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO Join BA and EL data to train data\n",
    "# TODO transform labels to one-hot encoding ?\n",
    "seq_tokenizer = SeqTokenizer()\n",
    "\n",
    "train_data = pHLAData(train_peptide_ba, train_hla_ba, hla_fp_dict, train_labels_ba, seq_tokenizer, max_peptide_len=MAX_PEPTIDE_LEN)\n",
    "\n",
    "# test_data = pHLAData(test_peptide, test_hla, hla_fp_dict, test_labels, seq_tokenizer, max_peptide_len=MAX_PEPTIDE_LEN)"
   ],
   "id": "d078e1179aa5ec2f",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:08:21.172981Z",
     "start_time": "2024-05-19T14:08:21.103364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "peptide_emb_dim = 10\n",
    "hla_fp_dim = 80\n",
    "pep_padding_idx = seq_tokenizer.padding_idx\n",
    "# make a dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=False)\n",
    "# test_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "# get a batch\n",
    "sample_peptide, sample_hla_fp, sample_label = next(iter(train_loader))\n",
    "\n",
    "print('INPUT DATA')\n",
    "print(f\"\\tSample peptide: {sample_peptide.shape}\")\n",
    "print(f\"\\tSample hla_fp: {sample_hla_fp.shape}\")\n",
    "print(f\"\\tSample label: {sample_label.shape}\")\n",
    "print('INSIDE MODEL')\n",
    "model = pHLAPredictor(p_emb_dim=peptide_emb_dim, hla_fp_dim=hla_fp_dim, padding_idx_seq=pep_padding_idx)\n",
    "peptide_mask = torch.ones((1, 15)).bool()\n",
    "hla_fp_mask = torch.ones((1, 36)).bool()\n",
    "\n",
    "pred =  model(sample_peptide, sample_hla_fp, peptide_mask, hla_fp_mask)"
   ],
   "id": "75d027a7ca601d01",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT DATA\n",
      "\tSample peptide: torch.Size([1, 15])\n",
      "\tSample hla_fp: torch.Size([1, 36, 80])\n",
      "\tSample label: torch.Size([1, 2])\n",
      "INSIDE MODEL\n",
      "pep_emb shape: torch.Size([1, 15, 10])\n",
      "interactions shape: torch.Size([1, 15, 4])\n",
      "logits shape: torch.Size([1, 15, 4])\n",
      "pred shape: torch.Size([1, 2])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparing train and evaluation",
   "id": "dd94685868867e37"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T22:21:50.458806Z",
     "start_time": "2024-05-19T22:21:50.445564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model, train_loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    peptide_mask = torch.ones((1, 15)).bool().to(device)\n",
    "    hla_fp_mask = torch.ones((1, 36)).bool().to(device)\n",
    "    acc = torchmetrics.Accuracy(task='multiclass', num_classes=2).to(device)\n",
    "    # proportion of positive identifications that are actually correct\n",
    "    precision = torchmetrics.Precision(task='multiclass', num_classes=2).to(device)\n",
    "    # proportion of actual positives that are correctly identified\n",
    "    recall = torchmetrics.Recall(task='multiclass', num_classes=2).to(device) \n",
    "    prob_pos_list, prob_neg_list = [], []\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        peptides, hla_fps, labels = data\n",
    "        peptides, hla_fps, labels = peptides.to(device), hla_fps.to(device), labels.to(device)    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(peptides, hla_fps, peptide_mask, hla_fp_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # convert labels from one-hot to integer representing the class\n",
    "        binary_labels = torch.argmax(labels, dim=1)\n",
    "        acc(outputs, binary_labels)\n",
    "        precision(outputs, binary_labels)\n",
    "        recall(outputs, binary_labels)\n",
    "        negative_probs = outputs[:, 0][binary_labels == 0].cpu().detach().numpy()\n",
    "        positive_probs = outputs[:, 1][binary_labels == 1].cpu().detach().numpy()\n",
    "        prob_neg_list.extend(negative_probs.tolist())\n",
    "        prob_pos_list.extend(positive_probs.tolist())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    epoch_acc = acc.compute()\n",
    "    epoch_precision = precision.compute()\n",
    "    epoch_recall = recall.compute()\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    mean_prob_neg = np.mean(prob_neg_list)\n",
    "    mean_prob_pos = np.mean(prob_pos_list)\n",
    "        \n",
    "    return epoch_loss, epoch_acc, epoch_precision, epoch_recall, mean_prob_neg, mean_prob_pos\n",
    "\n",
    "def eval_one_epoch(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    peptide_mask = torch.ones((1, 15)).bool().to(device)\n",
    "    hla_fp_mask = torch.ones((1, 36)).bool().to(device)\n",
    "    acc = torchmetrics.Accuracy(task='multiclass', num_classes=2).to(device)\n",
    "    # proportion of positive identifications that are actually correct\n",
    "    precision = torchmetrics.Precision(task='multiclass', num_classes=2).to(device)\n",
    "    # proportion of actual positives that are correctly identified\n",
    "    recall = torchmetrics.Recall(task='multiclass', num_classes=2).to(device)\n",
    "    prob_pos_list, prob_neg_list = [], []\n",
    "\n",
    "    for i, data in enumerate(val_loader):\n",
    "        peptides, hla_fps, labels = data\n",
    "        peptides, hla_fps, labels = peptides.to(device), hla_fps.to(device), labels.to(device)    \n",
    "        outputs = model(peptides, hla_fps, peptide_mask, hla_fp_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # convert labels from one-hot to integer representing the class\n",
    "        binary_labels = torch.argmax(labels, dim=1)\n",
    "        acc(outputs, binary_labels)\n",
    "        precision(outputs, binary_labels)\n",
    "        recall(outputs, binary_labels)\n",
    "        negative_probs = outputs[:, 0][binary_labels == 0].cpu().detach().numpy()\n",
    "        positive_probs = outputs[:, 1][binary_labels == 1].cpu().detach().numpy()\n",
    "        prob_pos_list.extend(positive_probs.tolist())\n",
    "        prob_neg_list.extend(negative_probs.tolist())\n",
    "        running_loss += loss.item()\n",
    "    epoch_acc = acc.compute()\n",
    "    epoch_precision = precision.compute()\n",
    "    epoch_recall = recall.compute()\n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    mean_prob_neg = torch.mean(torch.tensor(prob_neg_list))\n",
    "    mean_prob_pos = torch.mean(torch.tensor(prob_pos_list))\n",
    "    return epoch_loss, epoch_acc, epoch_precision, epoch_recall, mean_prob_neg, mean_prob_pos\n",
    "\n",
    "def train(model, train_loader, val_loader,\n",
    "          optimizer, criterion, n_epochs, device,\n",
    "          checkpoint_path=None, logger=None):\n",
    "    model = model.to(device)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        train_loss, train_acc, train_precision, train_recall, train_prob_neg, train_prob_pos = train_one_epoch(\n",
    "            model, train_loader, optimizer, criterion, device)\n",
    "        val_loss, val_acc, val_precision, val_recall, val_prob_neg, val_prob_pos = eval_one_epoch(\n",
    "            model, val_loader, criterion, device)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        # save last and best model\n",
    "        if checkpoint_path:\n",
    "            torch.save(model.state_dict(),\n",
    "                       os.path.join(checkpoint_path, 'last_model.t7'))\n",
    "            if val_loss < best_val_loss:\n",
    "                torch.save(model.state_dict(),\n",
    "                           os.path.join(checkpoint_path, 'best_model.t7'))\n",
    "\n",
    "        print(\n",
    "            f'Epoch {epoch + 1}/{n_epochs} - Train Loss: {round(train_loss, 4)} - Val Loss: {round(val_loss, 4)} - Best Val Loss: {round(best_val_loss, 4)} - Train Acc: {train_acc} - Val Acc: {val_acc} - Train Precision: {train_precision} - Val Precision: {val_precision} - Train Recall: {train_recall} - Val Recall: {val_recall} - Train Prob Neg: {train_prob_neg} - Val Prob Neg: {val_prob_neg} - Train Prob Pos: {train_prob_pos} - Val Prob Pos: {val_prob_pos}')\n",
    "        if logger:\n",
    "            logger.info(\n",
    "                f'Epoch {epoch + 1}/{n_epochs} - Train Loss: {round(train_loss, 4)} - Val Loss: {round(val_loss, 4)} - Best Val Loss: {round(best_val_loss, 4)} - Train Acc: {train_acc} - Val Acc: {val_acc} - Train Precision: {train_precision} - Val Precision: {val_precision} - Train Recall: {train_recall} - Val Recall: {val_recall} - Train Prob Neg: {train_prob_neg} - Val Prob Neg: {val_prob_neg} - Train Prob Pos: {train_prob_pos} - Val Prob Pos: {val_prob_pos}')\n",
    "    return train_losses, train_acc, train_precision, train_recall, train_prob_neg, train_prob_pos, val_losses, val_acc, val_precision, val_recall, val_prob_neg, val_prob_pos\n",
    "\n",
    "\n",
    "def test(model, test_loader, device, compute_roc=False):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        peptides, hla_fps, labels = data\n",
    "        peptides, hla_fps, labels = peptides.to(device), hla_fps.to(device), labels.to(device)    \n",
    "        outputs = model(peptides, hla_fps, peptide_mask, hla_fp_mask)\n",
    "        outputs = torch.argmax(outputs, 1)\n",
    "        labels = torch.argmax(labels, 1)\n",
    "        y_true.append(labels.cpu().detach().numpy())\n",
    "        y_pred.append(outputs.cpu().detach().numpy())\n",
    "    print(f'y_true: {y_true}')\n",
    "    print(f'y_pred: {y_pred}')\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "    \n",
    "    if compute_roc:\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        # plot roc curve\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC AUC: {roc_auc}')\n",
    "        #plt.savefig(os.path.join(CHEKPOINT_FOLDER, 'roc_curve.png'))\n",
    "        plt.show()\n",
    "    return y_true, y_pred"
   ],
   "id": "be9a1c62839b76b8",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T14:10:08.933217Z",
     "start_time": "2024-05-19T14:10:08.930042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TODO Join BA and EL data to train data\n",
    "# TODO transform labels to one-hot encoding ?\n",
    "seq_tokenizer = SeqTokenizer()\n",
    "\n",
    "# train_data = pHLAData(train_peptide_ba, train_hla_ba, hla_fp_dict, train_labels_ba, seq_tokenizer, max_peptide_len=MAX_PEPTIDE_LEN)\n",
    "# test_data = pHLAData(test_peptide, test_hla, hla_fp_dict, test_labels, seq_tokenizer, max_peptide_len=MAX_PEPTIDE_LEN)\n",
    "# Sample of train test data\n",
    "train_data = pHLAData(train_peptide_ba[:10], train_hla_ba[:10], hla_fp_dict, train_labels_ba[:10], seq_tokenizer, max_peptide_len=MAX_PEPTIDE_LEN)\n",
    "test_data = pHLAData(test_peptide[:10], test_hla[:10], hla_fp_dict, test_labels[:10], seq_tokenizer, max_peptide_len=MAX_PEPTIDE_LEN)"
   ],
   "id": "c5045590c6330e23",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T21:54:36.360134Z",
     "start_time": "2024-05-19T21:54:36.038390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EXP_NAME = 'pHLA_predictor'\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 1\n",
    "PEPTIDE_EMB_DIM = 10 # Can be changed\n",
    "HLA_FP_DIM = 80 # Fixed\n",
    "CHECKPOINT_FOLDER = os.path.join('.', 'checkpoints', EXP_NAME)\n",
    "logname = os.path.join(CHECKPOINT_FOLDER, 'train_log.log')\n",
    "logging.basicConfig(filename=logname,\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s - %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.DEBUG)\n",
    "LOGGER = logging.getLogger(EXP_NAME)\n",
    "\n",
    "os.makedirs(CHECKPOINT_FOLDER, exist_ok=True)\n",
    "pep_padding_idx = seq_tokenizer.padding_idx\n",
    "\n",
    "# Make data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=2, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(test_data, batch_size=1, shuffle=True)\n",
    "\n",
    "# Create model\n",
    "model = pHLAPredictor(p_emb_dim=PEPTIDE_EMB_DIM, hla_fp_dim=HLA_FP_DIM, padding_idx_seq=pep_padding_idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(model)\n",
    "LOGGER.info(model)\n",
    "\n",
    "out_metrics = train(model, train_loader, val_loader, optimizer, criterion, N_EPOCHS, DEVICE, checkpoint_path=CHECKPOINT_FOLDER, logger=LOGGER)\n",
    "\n",
    "train_losses, train_acc, train_precision, train_recall, train_prob_neg, train_prob_pos, val_losses, val_acc, val_precision, val_recall, val_prob_neg, val_prob_pos = out_metrics\n",
    "\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('CrossEntropyLoss')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(CHECKPOINT_FOLDER, 'loss.png'))\n",
    "plt.show()\n",
    "\n",
    "with open(os.path.join(CHECKPOINT_FOLDER, 'train_val_metrics.csv'), 'w') as f:\n",
    "    f.write('train_loss,val_loss,train_acc,val_acc,train_precision,val_precision,train_recall,val_recall,train_prob_neg,val_prob_neg,train_prob_pos,val_prob_pos\\n')\n",
    "    for train_loss, val_loss in zip(train_losses, val_losses):\n",
    "        f.write(f'{train_loss},{val_loss},{train_acc},{val_acc},{train_precision},{val_precision},{train_recall},{val_recall}\\n')"
   ],
   "id": "867627f422527680",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pHLAPredictor(\n",
      "  (peptide_embedding): Embedding(21, 10, padding_idx=0)\n",
      "  (joint_cross_attns): ModuleList(\n",
      "    (0): PepHLAJointCrossAttentionBlock(\n",
      "      (joint_cross_attn): BidirectionalCrossAttention(\n",
      "        (norm): Identity()\n",
      "        (context_norm): Identity()\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (context_dropout): Dropout(p=0.0, inplace=False)\n",
      "        (to_qk): Linear(in_features=10, out_features=256, bias=False)\n",
      "        (context_to_qk): Linear(in_features=80, out_features=256, bias=False)\n",
      "        (to_v): Linear(in_features=10, out_features=256, bias=False)\n",
      "        (context_to_v): Linear(in_features=80, out_features=256, bias=False)\n",
      "        (to_out): Linear(in_features=256, out_features=10, bias=True)\n",
      "        (context_to_out): Linear(in_features=256, out_features=80, bias=True)\n",
      "        (talking_heads): Identity()\n",
      "        (context_talking_heads): Identity()\n",
      "      )\n",
      "      (peptide_ff): Sequential(\n",
      "        (0): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
      "        (1): Linear(in_features=10, out_features=40, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Dropout(p=0.0, inplace=False)\n",
      "        (4): Linear(in_features=40, out_features=10, bias=True)\n",
      "      )\n",
      "      (hla_fp_ff): Sequential(\n",
      "        (0): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
      "        (1): Linear(in_features=80, out_features=320, bias=True)\n",
      "        (2): GELU(approximate='none')\n",
      "        (3): Dropout(p=0.0, inplace=False)\n",
      "        (4): Linear(in_features=320, out_features=80, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (filip): FILIP()\n",
      "  (linear_to_logits): Linear(in_features=4, out_features=4, bias=True)\n",
      "  (to_pred): Sequential(\n",
      "    (0): Reduce('... n d -> ... d', 'mean')\n",
      "    (1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  )\n",
      "  (to_read_value_aux_loss): ReadValueMLP(\n",
      "    (logits_norm): Sequential(\n",
      "      (0): Reduce('b n d -> b d', 'mean')\n",
      "      (1): LayerNorm((4,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=262, out_features=8, bias=True)\n",
      "      (1): GELU(approximate='none')\n",
      "      (2): Linear(in_features=8, out_features=1, bias=True)\n",
      "      (3): Rearrange('... 1 -> ...')\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]/home/bsccns/miniconda3/envs/tcells/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/bsccns/miniconda3/envs/tcells/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/tmp/ipykernel_28468/3245277753.py:65: RuntimeWarning: Mean of empty slice.\n",
      "  mean_prob_neg_list.append(negative_probs.mean())\n",
      "/home/bsccns/miniconda3/envs/tcells/lib/python3.11/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 2/2 [00:00<00:00, 12.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Train Loss: 0.8176 - Val Loss: 0.6821 - Best Val Loss: inf - Train Acc: 0.0 - Val Acc: 0.800000011920929 - Train Precision: 0.0 - Val Precision: 0.800000011920929 - Train Recall: 0.0 - Val Recall: 0.800000011920929 - Train Prob Neg: nan - Train Prob Pos: 0.38628373146057127\n",
      "Epoch 2/2 - Train Loss: 0.6341 - Val Loss: 0.5844 - Best Val Loss: inf - Train Acc: 1.0 - Val Acc: 1.0 - Train Precision: 1.0 - Val Precision: 1.0 - Train Recall: 1.0 - Val Recall: 1.0 - Train Prob Neg: nan - Train Prob Pos: 0.5612352907657623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee1ad8fbf61d2550"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cd780020446d3aad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a2514a347c1983de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
