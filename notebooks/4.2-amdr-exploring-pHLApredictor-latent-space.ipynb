{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Explore pHLApredictor latent spaces\n",
    "\n",
    "Check if the latent spaces of pHLApredictor models are able to capture the biological information of the input data, such as the peptide binding mode.\n",
    "\n"
   ],
   "id": "680d1c460dd88ef5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Useful functions and global variables",
   "id": "ff71ba349bf1da25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from nimbus.predictors import pHLABindingPredictor, pHLAPseudoseqBindingPredictor\n",
    "from nimbus.data_processing import SeqTokenizer\n",
    "from nimbus.data_processing import pHLADataset\n",
    "from nimbus.utils import LoggerFactory\n",
    "from nimbus.globals import DEVICE\n",
    "\n",
    "logger = LoggerFactory.get_logger('explore_pHLApredictor_nb', 'INFO')"
   ],
   "id": "9d9ba39725d3931d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_DIR = '../data'\n",
    "RAW_DATA = os.path.join(DATA_DIR, 'raw')\n",
    "PROCESSED_DATA = os.path.join(DATA_DIR, 'processed')\n",
    "HLA_FP_DIR = os.path.join(PROCESSED_DATA, 'hla_fingerprints')\n",
    "hla_fp_data_file = os.path.join(HLA_FP_DIR, 'hla_index_netMHCpan_pseudoseq_res_representation.csv')\n",
    "hla_fp_400_file = os.path.join(HLA_FP_DIR, 'hla_af_patch_emb_patch_r18_pt400.npy')\n",
    "hla_fp_36_file = os.path.join(HLA_FP_DIR, 'hla_fingerprint_netMHCpan_pseudoseq_res_representation.npy')\n",
    "hla_pseudoseq_file = os.path.join(RAW_DATA, 'pHLA_binding', 'NetMHCpan_train', 'MHC_pseudo_fixed.dat')\n",
    "test_netmhcpan_data_file = os.path.join(PROCESSED_DATA, 'pHLA_binding', 'test_set_peptides_data_MaxLenPep15_hla_ABC.csv.gz')\n",
    "RND_PEPTIDES_DIR = os.path.join(PROCESSED_DATA, 'cleaved_human_proteome')\n",
    "RND_PEPTIDES_FILES = glob.glob(os.path.join(RND_PEPTIDES_DIR, '*.txt'))\n",
    "\n",
    "# load rnd peptides data into dictionary\n",
    "rnd_peptides_data = {}\n",
    "for file in RND_PEPTIDES_FILES:\n",
    "    # Assuming filenames like random_peptides_length_9.txt\n",
    "    filename = os.path.basename(file).split('.')[0]\n",
    "    length = filename.split('_')[3]\n",
    "    with open(file, 'r') as f:\n",
    "        rnd_peptides_data[length] = f.read().splitlines()\n",
    "\n",
    "CHECKPOINTS_DIR = '../checkpoints/csv_logger'\n",
    "v_num = 0  # Version number\n",
    "experiments_dict = {\n",
    "    'pHLA_balance': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_balance', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_balance_hla_pseudoseq': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_balance_hla_pseudoseq', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_hla_pseudoseq': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_hla_pseudoseq', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_balance_FILIP128': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_balance_FILIP128', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_hla_pseudoseq_ManSplits0123_4': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_hla_pseudoseq_ManSplits0123_4', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_hla_pseudoseq_ManSplits0124_3': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_hla_pseudoseq_ManSplits0124_3', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_hla_pseudoseq_ManSplits0134_2': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_hla_pseudoseq_ManSplits0134_2', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_hla_pseudoseq_ManSplits0234_1': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_hla_pseudoseq_ManSplits0234_1', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_hla_pseudoseq_ManSplits1234_0': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_hla_pseudoseq_ManSplits1234_0', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pseudoseq_pHLA_imbalance_ManSplits0123_4': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pseudoseq_pHLA_imbalance_ManSplits0123_4', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 0,\n",
    "        'hla_representation_type': 'pseudoseq',\n",
    "    },\n",
    "    'pHLA_imbalance_newHLAFP_ManSplits0123_4': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_newHLAFP_ManSplits0123_4', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_EL_hla_pseudoseq_splitTrainTest': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_EL_hla_pseudoseq_splitTrainTest', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_EL_splitTrainTest': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_EL_splitTrainTest', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_hla_pseudoseq_AllBA_TestAsVal': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_hla_pseudoseq_AllBA_TestAsVal', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_hla_pseudoseq_AllEL_TestAsVal': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_hla_pseudoseq_AllEL_TestAsVal', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 36,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_newHLAFP_AllBA_TestAsVal': { # TODO test\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_newHLAFP_AllBA_TestAsVal', f'version_0', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_newHLAFP_AllBA_TestAsVal_v1': { # TODO test\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_newHLAFP_AllBA_TestAsVal', f'version_1', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_newHLAFP_AllEL_TestAsVal': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_newHLAFP_AllEL_TestAsVal', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pseudoseq_pHLA_imbalance_AllBA_TestAsVal': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pseudoseq_pHLA_imbalance_AllBA_TestAsVal', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 0,\n",
    "        'hla_representation_type': 'pseudoseq',\n",
    "    },\n",
    "    'pseudoseq_pHLA_imbalance_AllEL_TestAsVal': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pseudoseq_pHLA_imbalance_AllEL_TestAsVal', f'version_{v_num}', 'checkpoints','ep*'))[0],\n",
    "        'hla_fp_size': 0,\n",
    "        'hla_representation_type': 'pseudoseq',\n",
    "    },\n",
    "    'pHLA_imbalance_AllBA_HLAAugmented_ManSplit0123_4': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_AllBA_HLAAugmented_ManSplit0123_4', f'version_{v_num}', 'checkpoints','l*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "        'pHLA_imbalance_AllBA_HLAAugmented1Random_ManSplit0123_4': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_AllBA_HLAAugmented1Random_ManSplit0123_4', f'version_{v_num}', 'checkpoints','epoch13-val_loss0.2769-val_acc0.88.ckpt'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'pHLA_imbalance_AllBA_HLAAugmented1Random_ManSplit0123_4_v1': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'pHLA_imbalance_AllBA_HLAAugmented1Random_ManSplit0123_4', f'version_1', 'checkpoints','epoch06-val_loss0.2758-val_acc0.88.ckpt'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'Immuno_imbalance_PRIME2_ManSplit1234_0_HLAAugmented_pHLApretrained_Freeze_SA': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'Immuno_imbalance_PRIME2_ManSplit1234_0_HLAAugmented_pHLApretrained_Freeze_SA', f'version_{v_num}', 'checkpoints','epoch*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "    'Immuno_imbalance_PRIME2_ManSplit1234_0_HLAAugmented_pHLApretrained_Freeze_SA_CA_FILIP': {\n",
    "        'model_checkpoint': glob.glob(os.path.join(CHECKPOINTS_DIR, 'Immuno_imbalance_PRIME2_ManSplit1234_0_HLAAugmented_pHLApretrained_Freeze_SA_CA_FILIP', f'version_{v_num}', 'checkpoints','epoch*'))[0],\n",
    "        'hla_fp_size': 400,\n",
    "        'hla_representation_type': 'surface_fp',\n",
    "    },\n",
    "}"
   ],
   "id": "f34679c04dc489a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def load_pretrained_model(checkpoint_file, hla_representation_type='surface_fp'):\n",
    "    if hla_representation_type == 'surface_fp':\n",
    "        logger.info(f\"Loading pHLABindingPredictor pretrained model {checkpoint_file}\")\n",
    "        model = pHLABindingPredictor.load_from_checkpoint(checkpoint_file)\n",
    "    elif hla_representation_type == 'pseudoseq':\n",
    "        logger.info(f\"Loading pHLAPseudoseqBindingPredictor pretrained model {checkpoint_file}\")\n",
    "        model = pHLAPseudoseqBindingPredictor.load_from_checkpoint(checkpoint_file)\n",
    "    else:\n",
    "        logger.error(f\"Unknown hla_representation_type {hla_representation_type}. \"\n",
    "                     f\"Expected 'surface_fp' or 'pseudoseq'\")\n",
    "        sys.exit(1)\n",
    "    return model\n"
   ],
   "id": "b1b5dd8fe514c218",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_likelihood_from_dataloader(model, dataloader, device, save_attn=False):\n",
    "    all_probs = []\n",
    "    all_attn_dict = []\n",
    "    all_reps = []\n",
    "    model.eval()\n",
    "    for peptide_data_input, hla_data_input, label in dataloader:\n",
    "        if save_attn:\n",
    "            reps, attn_dict = model(torch.Tensor(peptide_data_input).to(device),\n",
    "                      torch.Tensor(hla_data_input).to(device), save_attn=save_attn)\n",
    "            all_attn_dict.append(attn_dict)\n",
    "        else:\n",
    "            # Only returns FILIP representation\n",
    "            reps = model(torch.Tensor(peptide_data_input).to(device),\n",
    "                          torch.Tensor(hla_data_input).to(device), save_attn=save_attn)\n",
    "        \n",
    "        logits = model.linear_to_logits(reps)\n",
    "        logits = model.to_pred(logits)\n",
    "        prob = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        all_probs.extend(prob.tolist())\n",
    "        all_reps.append(reps.detach().cpu().numpy())\n",
    "        \n",
    "    reps_arr = np.concatenate(all_reps, axis=0)\n",
    "\n",
    "    if save_attn:\n",
    "        # merge dicts\n",
    "        merged_attns_dict = {}\n",
    "        \n",
    "        for attn_type in all_attn_dict[0].keys():\n",
    "            if 'filip' in attn_type:\n",
    "                filip_interactions = [attn_dict[attn_type] for attn_dict in all_attn_dict]\n",
    "                merged_attns_dict[attn_type] = np.concatenate(filip_interactions, axis=0)\n",
    "            else:\n",
    "                attn_list = []\n",
    "                attn_list.extend(np.array(attn_dict[attn_type]) for attn_dict in all_attn_dict)\n",
    "                merged_attns_dict[attn_type] = np.concatenate(attn_list, axis=1)\n",
    "        \n",
    "        return all_probs, reps_arr, merged_attns_dict \n",
    "    else:\n",
    "        return all_probs, reps_arr\n",
    "        "
   ],
   "id": "e4f36b70eb501e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_likelihood(model, seq: str, hla_fp, hla_fp_data, device, save_attn=False):\n",
    "    \"\"\"Predict the likelihood of a peptide binding to a set of HLA alleles in hla_fp.\"\"\"\n",
    "    tokenizer = SeqTokenizer()\n",
    "    pe = np.zeros(15, dtype='int32')\n",
    "    pe[:len(seq)] = tokenizer.encode(seq)\n",
    "\n",
    "    peptide_data_input = []\n",
    "    hla_data_input = []\n",
    "    for fp in hla_fp:\n",
    "        peptide_data_input.append(pe)\n",
    "        hla_data_input.append(fp)\n",
    "    peptide_data_input = np.array(peptide_data_input).reshape(len(peptide_data_input), 1, -1)\n",
    "    hla_data_input = np.array(hla_data_input)\n",
    "    \n",
    "    model.eval()\n",
    "    if save_attn:\n",
    "        reps, attn_dict = model(torch.Tensor(peptide_data_input).to(device),\n",
    "                      torch.Tensor(hla_data_input).to(device), save_attn=save_attn)\n",
    "    else:\n",
    "        # Only returns FILIP representation\n",
    "        reps = model(torch.Tensor(peptide_data_input).to(device),\n",
    "                      torch.Tensor(hla_data_input).to(device), save_attn=save_attn)\n",
    "        \n",
    "    logits = model.linear_to_logits(reps)\n",
    "    logits = model.to_pred(logits)\n",
    "    prob = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "    \n",
    "    hla_fp_data_rev = {v: k for k,v in hla_fp_data.items()}\n",
    "    \n",
    "    # Create a dictionary with the probabilities for each HLA allele. \n",
    "    # Importantly, they are not sorted by probability to keep the order of the HLA alleles. \n",
    "    prob_by_hla = {h: v for h, v in zip(hla_fp_data.keys(), prob)}\n",
    "\n",
    "    ranked_order = prob.argsort()[::-1]\n",
    "    hla_list = [hla_fp_data_rev[x] for x in ranked_order]\n",
    "    p_list = [prob[x] for x in ranked_order]\n",
    "    \n",
    "    \n",
    "    for i, (h, p) in enumerate(zip(hla_list, p_list)):\n",
    "        if i>4: break\n",
    "        print(f'{h}:  {p}')\n",
    "    \n",
    "    if save_attn:\n",
    "        return prob_by_hla, reps.detach().cpu().numpy(), attn_dict \n",
    "    else:\n",
    "        return prob_by_hla, reps.detach().cpu().numpy()"
   ],
   "id": "69fea21745ff843f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def predict_likelihood_several_peptides(model, seq: list, hla_fp, hla_fp_data, device, save_attn=False):\n",
    "    \"\"\"Predict the likelihood of list of peptide binding to a set of HLA alleles in hla_fp.\"\"\"\n",
    "    tokenizer = SeqTokenizer()\n",
    "    peptide_data_input = []\n",
    "    hla_data_input = []\n",
    "\n",
    "    for s in seq:\n",
    "        pe = np.zeros(15, dtype='int32')\n",
    "        pe[:len(s)] = tokenizer.encode(s)\n",
    "        for fp in hla_fp:\n",
    "            peptide_data_input.append(pe)\n",
    "            hla_data_input.append(fp)\n",
    "    peptide_data_input = np.array(peptide_data_input).reshape(len(peptide_data_input), 1, -1)\n",
    "    hla_data_input = np.array(hla_data_input)\n",
    "    \n",
    "    model.eval()\n",
    "    if save_attn:\n",
    "        reps, attn_dict = model(torch.Tensor(peptide_data_input).to(device),\n",
    "                      torch.Tensor(hla_data_input).to(device), save_attn=save_attn)\n",
    "    else:\n",
    "        # Only returns FILIP representation\n",
    "        reps = model(torch.Tensor(peptide_data_input).to(device),\n",
    "                      torch.Tensor(hla_data_input).to(device), save_attn=save_attn)\n",
    "        \n",
    "    logits = model.linear_to_logits(reps)\n",
    "    logits = model.to_pred(logits)\n",
    "    prob = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "    \n",
    "    hla_fp_data_rev = {v: k for k,v in hla_fp_data.items()}\n",
    "    \n",
    "    all_peptides_prob_by_phla= {}\n",
    "    # Print the top 5 HLA alleles for each peptide\n",
    "    for n_pep in range(len(seq)):\n",
    "        print(f'Peptide: {seq[n_pep]}')\n",
    "        initial_idx = n_pep * len(hla_fp)\n",
    "        last_idx = initial_idx + len(hla_fp)\n",
    "        pep_prob = prob[initial_idx:last_idx]\n",
    "        # Create a dictionary with the probabilities for each HLA allele. \n",
    "        # Importantly, they are not sorted by probability to keep the order of the HLA alleles. \n",
    "        prob_by_phla = {f'{seq[n_pep]}_{h}': v for h, v in zip(hla_fp_data.keys(), pep_prob)}\n",
    "        ranked_order = pep_prob.argsort()[::-1]\n",
    "\n",
    "        hla_list = [hla_fp_data_rev[x] for x in ranked_order]\n",
    "        p_list = [pep_prob[x] for x in ranked_order]\n",
    "        for i, (h, p) in enumerate(zip(hla_list, p_list)):\n",
    "            if i>4: break\n",
    "            print(f'{h}:  {p}')\n",
    "        all_peptides_prob_by_phla.update(prob_by_phla)\n",
    "    \n",
    "    if save_attn:\n",
    "        return all_peptides_prob_by_phla, reps.detach().cpu().numpy(), attn_dict \n",
    "    else:\n",
    "        return all_peptides_prob_by_phla, reps.detach().cpu().numpy()\n"
   ],
   "id": "27be68a457c5f143",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def select_pool_hla_fp(list_hla_names, hla_fp, hla_fp_data):\n",
    "    \"\"\"Returns a shortlist of hla_fp and hla_fp_data for a list of HLA alleles.\"\"\"\n",
    "    hla_fp_shortlist = []\n",
    "    hla_fp_data_shortlist = {}\n",
    "    for hla_name in list_hla_names:\n",
    "        hla_fp_shortlist.append(hla_fp[hla_fp_data[hla_name]])\n",
    "        hla_fp_data_shortlist[hla_name] = len(hla_fp_shortlist) - 1\n",
    "    return np.array(hla_fp_shortlist), hla_fp_data_shortlist"
   ],
   "id": "d36c7ecb2d26a61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Case study 1:\n",
    "\n",
    "A molecular switch in immunodominant HIV-1-specific CD8 T-cell epitopes shapes differential HLA-restricted escape - Retrovirology https://link.springer.com/article/10.1186/s12977-015-0149-5\n",
    "\n",
    "### Info from the paper\n",
    "\n",
    "We studied four members of the HLA-B7 superfamily, HLA-B\\*07:02, HLA-B\\*42:01, HLA-B\\*42:02 and HLA-B\\*81:01. These closely-related HLAI molecules restrict both distinct and identical HIV-1 epitopes\n",
    "The differences in sequence between HLA-B\\*07:02, B\\*42:01, B\\*42:02 and B\\*81:01 are small [...] all of the polymorphic positions are part of the HLA peptide binding pockets and therefore potentially affect peptide presentation to CD8+ T cells.\n",
    "\n",
    "We focused on two epitopes, TL9-p24 and RM9-Nef, that dominate the HIV-1-specific CD8 T-cell response in the Southern African HIV-1 epidemic.\n",
    "These two epitopes were presented by all four of these HLA molecules, other than TL9-p24 which was presented by all except HLA-B\\*42:02 (Figure 2A). TL9-p24, dominantly targeted through HLA-B\\*42:01 and HLA-B\\*81:01 and subdominantly through HLA-B\\*07:02 [...].\n",
    "RM9-Nef, however, was presented by all 4 different HLAs.\n",
    "\n",
    "[...]\n",
    "\n",
    "TL9-p24 exhibits a unique conformation when presented by HLA-B*81:01.\n",
    "\n",
    "### Summary\n",
    "\n",
    "#### TL9-p24\n",
    "Peptide: `TPQDLNTML`\n",
    "HLA alleles in which is presented:\n",
    "- HLA-B\\*42:01\n",
    "- HLA-B\\*81:01 (dominant, shows a unique peptide binding mode)\n",
    "- HLA-B\\*07:02 (subdominant)\n",
    "\n",
    "HLA alleles in which is not presented:\n",
    "- HLA-B\\*42:02\n",
    "\n",
    "#### RM9-Nef\n",
    "Peptide: `RPQVPLRPM`\n",
    "HLA alleles in which is presented:\n",
    "- HLA-B\\*07:02\n",
    "- HLA-B\\*42:01\n",
    "- HLA-B\\*42:02\n",
    "- HLA-B\\*81:01\n",
    "\n"
   ],
   "id": "98bf6f571ebc6306"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "exp_name = 'Immuno_imbalance_PRIME2_ManSplit1234_0_HLAAugmented_pHLApretrained_Freeze_SA_CA_FILIP'#'pHLA_imbalance_AllBA_HLAAugmented_ManSplit0123_4' #'pHLA_imbalance_AllBA_HLAAugmented_ManSplit0123_4'#'pHLA_imbalance_newHLAFP_ManSplits0123_4'#'pHLA_imbalance_AllBA_HLAAugmented_ManSplit0123_4' #'pHLA_imbalance_hla_pseudoseq_ManSplits1234_0' #'pHLA_balance_hla_pseudoseq'\n",
    "hla_representation_type = experiments_dict[exp_name]['hla_representation_type']\n",
    "\n",
    "if hla_representation_type == 'surface_fp':\n",
    "    if 400 == experiments_dict[exp_name]['hla_fp_size']:\n",
    "        hla_fp_file = hla_fp_400_file\n",
    "    elif 36 == experiments_dict[exp_name]['hla_fp_size']:\n",
    "        hla_fp_file = hla_fp_36_file\n",
    "\n",
    "    hla_fp = np.load(hla_fp_file)\n",
    "    hla_fp_data = pd.read_csv(hla_fp_data_file,\n",
    "                              index_col=1,\n",
    "                              names=['index'],\n",
    "                              header=0).to_dict()['index']\n",
    "elif hla_representation_type == 'pseudoseq':\n",
    "    hla_fp_data = pd.read_csv(hla_fp_data_file,\n",
    "                              index_col=1,\n",
    "                              names=['index'],\n",
    "                              header=0).to_dict()['index']\n",
    "    hla_allels_subset = list(hla_fp_data.keys())\n",
    "    del hla_fp_data\n",
    "    hla_pseudoseq_dict = pd.read_csv(hla_pseudoseq_file, sep='\\s+', names=['pseudoseq'], header=None).to_dict()['pseudoseq']\n",
    "    # filter hla_pseudoseq_dict to only include the alleles in hla_allels_subset\n",
    "    hla_pseudoseq_dict = {hla: seq for hla, seq in hla_pseudoseq_dict.items() if hla in hla_allels_subset}\n",
    "    seq_tokenizer = SeqTokenizer()\n",
    "    hla_fp_dict = {hla: torch.Tensor(seq_tokenizer.encode(hla_pseudoseq_dict[hla]))\n",
    "                   for hla in hla_pseudoseq_dict.keys()}\n",
    "    hla_fp = list(hla_fp_dict.values())\n",
    "    # make hla_fp_data compatible with the rest of the code. It is a dictionary with the same keys as hla_fp and indexes as values\n",
    "    hla_fp_data = {hla: i for i, hla in enumerate(hla_fp_dict.keys())}\n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError(f\"Unknown hla_representation_type {hla_representation_type}. Expected 'surface_fp' or 'pseudoseq'\")\n",
    "\n",
    "model = load_pretrained_model(experiments_dict[exp_name]['model_checkpoint'],\n",
    "                              hla_representation_type=hla_representation_type)"
   ],
   "id": "6a9ac1bebb7a0975",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### TL9-p24\n",
    "##### NetMHCpan baseline\n",
    "They cannot differentiate between HLA-B\\*42:01 and HLA-B\\*42:02 because HLA-B\\*42:02 predictions are based on the nearest neighbor HLA-B\\*42:01. \n",
    "```\n",
    "# NetMHCpan version 4.1b\n",
    "\n",
    "# Tmpdir made /var/www/html/services/NetMHCpan-4.1/tmp/netMHCpanvigqPD\n",
    "# Input is in FSA format\n",
    "\n",
    "# Peptide length 9\n",
    "\n",
    "# Make EL predictions\n",
    "\n",
    "HLA-B42:01 : Distance to training data  0.000 (using nearest neighbor HLA-B42:01)\n",
    "HLA-B81:01 : Distance to training data  0.146 (using nearest neighbor HLA-B42:01)\n",
    "HLA-B07:02 : Distance to training data  0.000 (using nearest neighbor HLA-B07:02)\n",
    "HLA-B42:02 : Distance to training data  0.028 (using nearest neighbor HLA-B42:01)\n",
    "\n",
    "# Rank Threshold for Strong binding peptides   0.500\n",
    "# Rank Threshold for Weak binding peptides   2.000\n",
    "---------------------------------------------------------------------------------------------------------------------------\n",
    " Pos         MHC        Peptide      Core Of Gp Gl Ip Il        Icore        Identity  Score_EL %Rank_EL BindLevel\n",
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "   1 HLA-B*42:01      TPQDLNTML TPQDLNTML  0  0  0  0  0    TPQDLNTML        Sequence 0.9286300    0.069 <= SB\n",
    "   1 HLA-B*81:01      TPQDLNTML TPQDLNTML  0  0  0  0  0    TPQDLNTML        Sequence 0.7545360    0.040 <= SB\n",
    "   1 HLA-B*07:02      TPQDLNTML TPQDLNTML  0  0  0  0  0    TPQDLNTML        Sequence 0.7424500    0.189 <= SB\n",
    "   1 HLA-B*42:02      TPQDLNTML TPQDLNTML  0  0  0  0  0    TPQDLNTML        Sequence 0.6575040    0.076 <= SB\n",
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "```"
   ],
   "id": "a7f80c5f6e5ba7cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "seq = 'TPQDLNTML'\n",
    "save_attention = True\n",
    "if save_attention:\n",
    "    prob_by_hla, reps, attns_dict = predict_likelihood(model, seq, hla_fp, hla_fp_data, DEVICE, save_attn=save_attention)\n",
    "else:\n",
    "    prob_by_hla, reps = predict_likelihood(model, seq, hla_fp, hla_fp_data, DEVICE)"
   ],
   "id": "1a686853eaa96e36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('HLA of interest and their probabilities:')\n",
    "print('\\t Binders:')\n",
    "print('HLA-B*42:01:', prob_by_hla['HLA-B42-01'])\n",
    "print('HLA-B*81:01:', prob_by_hla['HLA-B81-01'])\n",
    "print('HLA-B*07:02:', prob_by_hla['HLA-B07-02'], '(subdominant)')\n",
    "print('\\t Non-binders:')\n",
    "print('HLA-B*42:02:', prob_by_hla['HLA-B42-02'])"
   ],
   "id": "3f1ff1adef94332f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "reps.shape",
   "id": "604cf4a879062557",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "px.bar(x=prob_by_hla.keys(), y=prob_by_hla.values(), range_y=[0, 1])",
   "id": "92409615f4dc2201",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "umap = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    ")\n",
    "\n",
    "coords = umap.fit_transform(reps.mean(1))"
   ],
   "id": "51b5b64dafdeed0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "symbol_dict = {'A': 'circle', 'B': 'x', 'C': 'diamond'}\n",
    "size_dict = {'A': 10, 'B': 12, 'C': 12}\n",
    "\n",
    "fig.add_traces(\n",
    "    go.Scatter(\n",
    "        x = coords[:, 0],\n",
    "        y = coords[:, 1],\n",
    "        mode='markers',\n",
    "        marker = dict(\n",
    "            color = list(prob_by_hla.values()),\n",
    "            colorscale='Portland_r',\n",
    "            symbol = [symbol_dict[x.split('-')[1][0]] for x in list(prob_by_hla.keys())],\n",
    "            size = [size_dict[x.split('-')[1][0]] for x in list(prob_by_hla.keys())],\n",
    "            showscale = True,\n",
    "            opacity = [1 if h in ['HLA-B42-01', 'HLA-B42-02', 'HLA-B81-01', 'HLA-B07-02'] else 0.3 for h in prob_by_hla.keys()],\n",
    "            colorbar=dict(\n",
    "                len=0.75,\n",
    "                title_text='binding score',\n",
    "                xanchor=\"right\", x=1.3,\n",
    "                yanchor='bottom', y=0.1,\n",
    "                thickness=20,\n",
    "            ),\n",
    "            line=dict(width=1)\n",
    "        ),\n",
    "        hovertext = [f'name: {n}<br>prob: {p}' for n, p in zip(list(prob_by_hla.keys()), prob_by_hla.values())]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    # showlegend=True,\n",
    "    font={'family': \"Arial\"}, width=800, height=800,\n",
    "    xaxis_title='UMAP 1',\n",
    "    yaxis_title='UMAP 2',\n",
    "\n",
    "    )\n",
    "\n"
   ],
   "id": "e933911311673a1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for attn_type, attn_arr in attns_dict.items():\n",
    "    if attn_type.startswith('filip'):\n",
    "        print(f'{attn_type} has {len(attn_arr)} BatchSize each batch with shape {attn_arr[0].shape}. So the object shape is {attn_arr.shape}')        \n",
    "    else:\n",
    "        print(f'{attn_type} has {len(attn_arr)} layers each with shape {attn_arr[0].shape} each') "
   ],
   "id": "6ca875d19a34746b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "filip_interactions = attns_dict['filip_interactions']\n",
    "hla_name = 'HLA-B42-01'\n",
    "hla_index = hla_fp_data[hla_name]\n",
    "head_idx = [2,4,5,11,12,13, 50, 63]\n",
    "#head_idx = [124, 125, 126, 127]\n",
    "\n",
    "# Find the global min and max values across all the heatmaps\n",
    "global_min = min(hla.min() for hla in filip_interactions[hla_index][head_idx])\n",
    "global_max = max(hla.max() for hla in filip_interactions[hla_index][head_idx])\n",
    "\n",
    "fig = sp.make_subplots(rows=1, cols=len(head_idx), subplot_titles=[f'{hla_name}_H{i}' for i in head_idx])\n",
    "\n",
    "for i, hla in enumerate(filip_interactions[hla_index][head_idx]):\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hla,\n",
    "            colorscale='Portland_r',\n",
    "            zmin=global_min,  # Set the same minimum value\n",
    "            zmax=global_max   # Set the same maximum value\n",
    "        ),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    width=150 * len(head_idx),\n",
    "    showlegend=False,\n",
    "    title_text=\"HLA Interactions\"\n",
    ")\n",
    "\n",
    "# Update the x-axis and y-axis labels for each subplot\n",
    "for i in range(len(head_idx)):\n",
    "    fig.update_xaxes(title_text=\"Peptide Sequence\", row=1, col=i+1)\n",
    "fig.update_yaxes(title_text=\"HLA Fingerprint\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    # showlegend=True,\n",
    "    font={'family': \"Arial\"},\n",
    "    )\n",
    "fig.show()"
   ],
   "id": "84f88075def2e5dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "attn_layer = 3\n",
    "pep_cross_attn = attns_dict['pep_cross_attn'][attn_layer] # Shape: (num_layers, batch_size, num_heads, hla_n_fp, pep_seq_len)\n",
    "hla_name = 'HLA-B42-01'\n",
    "hla_index = hla_fp_data[hla_name]\n",
    "head_idx = [0,1,2,3,4,5,6,7]\n",
    "#head_idx = [124, 125, 126, 127]\n",
    "\n",
    "# Find the global min and max values across all the heatmaps\n",
    "global_min = min(hla.min() for hla in pep_cross_attn[hla_index][head_idx])\n",
    "global_max = max(hla.max() for hla in pep_cross_attn[hla_index][head_idx])\n",
    "\n",
    "fig = sp.make_subplots(rows=1, cols=len(head_idx), subplot_titles=[f'Layer{attn_layer}_Head{i}' for i in head_idx])\n",
    "\n",
    "for i, hla in enumerate(pep_cross_attn[hla_index][head_idx]):\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hla,\n",
    "            colorscale='Portland_r',\n",
    "            zmin=global_min,  # Set the same minimum value\n",
    "            zmax=global_max   # Set the same maximum value\n",
    "        ),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    width=150 * len(head_idx),\n",
    "    showlegend=False,\n",
    "    title_text=f\"Peptide Cross Attn with {hla_name}\"\n",
    ")\n",
    "\n",
    "# Update the x-axis and y-axis labels for each subplot\n",
    "for i in range(len(head_idx)):\n",
    "    fig.update_xaxes(title_text=\"Peptide Sequence\", row=1, col=i+1)\n",
    "fig.update_yaxes(title_text=\"HLA Fingerprint\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    # showlegend=True,\n",
    "    font={'family': \"Arial\"},\n",
    "    )\n",
    "fig.show()"
   ],
   "id": "db523f8eb3e7a276",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This might give information of which peptide residues are pointing towards\n",
    "# the inner binding groove of the HLA\n",
    "\n",
    "attn_layer = 3\n",
    "pep_cross_attn = attns_dict['hla_cross_attn'][attn_layer] # Shape: (num_layers, batch_size, num_heads, hla_n_fp, pep_seq_len)\n",
    "hla_name = 'HLA-B42-01'\n",
    "hla_index = hla_fp_data[hla_name]\n",
    "head_idx = [0,1,2,3,4,5,6,7]\n",
    "#head_idx = [124, 125, 126, 127]\n",
    "\n",
    "# Find the global min and max values across all the heatmaps\n",
    "global_min = min(hla.min() for hla in pep_cross_attn[hla_index][head_idx])\n",
    "global_max = max(hla.max() for hla in pep_cross_attn[hla_index][head_idx])\n",
    "\n",
    "fig = sp.make_subplots(rows=1, cols=len(head_idx), subplot_titles=[f'Layer{attn_layer}_Head{i}' for i in head_idx])\n",
    "\n",
    "for i, hla in enumerate(pep_cross_attn[hla_index][head_idx]):\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hla,\n",
    "            colorscale='Portland_r',\n",
    "            zmin=global_min,  # Set the same minimum value\n",
    "            zmax=global_max   # Set the same maximum value\n",
    "        ),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=800,\n",
    "    width=150 * len(head_idx),\n",
    "    showlegend=False,\n",
    "    title_text=f\"HLA Cross Attn with {hla_name}\"\n",
    ")\n",
    "\n",
    "# Update the x-axis and y-axis labels for each subplot\n",
    "for i in range(len(head_idx)):\n",
    "    fig.update_xaxes(title_text=\"Peptide Sequence\", row=1, col=i+1)\n",
    "fig.update_yaxes(title_text=\"HLA Fingerprint\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    # showlegend=True,\n",
    "    font={'family': \"Arial\"},\n",
    "    )\n",
    "fig.show()"
   ],
   "id": "74d43770105704e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This might give information of which peptide residues are pointing towards\n",
    "# the inner binding groove of the HLA\n",
    "\n",
    "attn_layer = 0\n",
    "pep_cross_attn = attns_dict['hla_self_attn'][attn_layer] # Shape: (num_layers, batch_size, num_heads, hla_n_fp, pep_seq_len)\n",
    "hla_name = 'HLA-B42-01'\n",
    "hla_index = hla_fp_data[hla_name]\n",
    "head_idx = [0,1,2,3,4,5,6,7]\n",
    "#head_idx = [124, 125, 126, 127]\n",
    "\n",
    "# Find the global min and max values across all the heatmaps\n",
    "global_min = min(hla.min() for hla in pep_cross_attn[hla_index][head_idx])\n",
    "global_max = max(hla.max() for hla in pep_cross_attn[hla_index][head_idx])\n",
    "\n",
    "fig = sp.make_subplots(rows=1, cols=len(head_idx), subplot_titles=[f'Layer{attn_layer}_Head{i}' for i in head_idx])\n",
    "\n",
    "for i, hla in enumerate(pep_cross_attn[hla_index][head_idx]):\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hla,\n",
    "            colorscale='Portland_r',\n",
    "            zmin=global_min,  # Set the same minimum value\n",
    "            zmax=global_max   # Set the same maximum value\n",
    "        ),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=500 * len(head_idx),\n",
    "    showlegend=False,\n",
    "    title_text=f\"HLA Self-Attn with {hla_name}\"\n",
    ")\n",
    "\n",
    "# Update the x-axis and y-axis labels for each subplot\n",
    "for i in range(len(head_idx)):\n",
    "    fig.update_xaxes(title_text=\"Peptide Sequence\", row=1, col=i+1)\n",
    "fig.update_yaxes(title_text=\"HLA Fingerprint\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    # showlegend=True,\n",
    "    font={'family': \"Arial\"},\n",
    "    )\n",
    "fig.show()"
   ],
   "id": "5d5564888033b4c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# This might give information of which peptide residues are pointing towards\n",
    "# the inner binding groove of the HLA\n",
    "\n",
    "attn_layer = 1\n",
    "pep_cross_attn = attns_dict['pep_self_attn'][attn_layer] # Shape: (num_layers, batch_size, num_heads, hla_n_fp, pep_seq_len)\n",
    "hla_name = 'HLA-B42-01'\n",
    "hla_index = hla_fp_data[hla_name]\n",
    "head_idx = [0,1,2,3,4,5,6,7]\n",
    "\n",
    "# Find the global min and max values across all the heatmaps\n",
    "global_min = min(hla.min() for hla in pep_cross_attn[hla_index][head_idx])\n",
    "global_max = max(hla.max() for hla in pep_cross_attn[hla_index][head_idx])\n",
    "\n",
    "fig = sp.make_subplots(rows=1, cols=len(head_idx), subplot_titles=[f'Layer{attn_layer}_Head{i}' for i in head_idx])\n",
    "\n",
    "for i, hla in enumerate(pep_cross_attn[hla_index][head_idx]):\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=hla,\n",
    "            colorscale='Portland_r',\n",
    "            zmin=global_min,  # Set the same minimum value\n",
    "            zmax=global_max   # Set the same maximum value\n",
    "        ),\n",
    "        row=1, col=i+1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=500 * len(head_idx),\n",
    "    showlegend=False,\n",
    "    title_text=f\"Peptide Self-Attn with {hla_name}\"\n",
    ")\n",
    "\n",
    "# Update the x-axis and y-axis labels for each subplot\n",
    "for i in range(len(head_idx)):\n",
    "    fig.update_xaxes(title_text=\"Peptide Sequence\", row=1, col=i+1)\n",
    "fig.update_yaxes(title_text=\"HLA Fingerprint\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    # showlegend=True,\n",
    "    font={'family': \"Arial\"},\n",
    "    )\n",
    "fig.show()"
   ],
   "id": "1f64ebbd5e432ed6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### RM9-Nef\n",
    "##### NetMHCpan baseline\n",
    "```\n",
    "# NetMHCpan version 4.1b\n",
    "\n",
    "# Tmpdir made /var/www/html/services/NetMHCpan-4.1/tmp/netMHCpandu0tne\n",
    "# Input is in FSA format\n",
    "\n",
    "# Peptide length 9\n",
    "\n",
    "# Make EL predictions\n",
    "\n",
    "HLA-B42:01 : Distance to training data  0.000 (using nearest neighbor HLA-B42:01)\n",
    "HLA-B81:01 : Distance to training data  0.146 (using nearest neighbor HLA-B42:01)\n",
    "HLA-B07:02 : Distance to training data  0.000 (using nearest neighbor HLA-B07:02)\n",
    "HLA-B42:02 : Distance to training data  0.028 (using nearest neighbor HLA-B42:01)\n",
    "\n",
    "# Rank Threshold for Strong binding peptides   0.500\n",
    "# Rank Threshold for Weak binding peptides   2.000\n",
    "---------------------------------------------------------------------------------------------------------------------------\n",
    " Pos         MHC        Peptide      Core Of Gp Gl Ip Il        Icore        Identity  Score_EL %Rank_EL BindLevel\n",
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "   1 HLA-B*42:01      RPQVPLRPM RPQVPLRPM  0  0  0  0  0    RPQVPLRPM        Sequence 0.9776250    0.022 <= SB\n",
    "   1 HLA-B*81:01      RPQVPLRPM RPQVPLRPM  0  0  0  0  0    RPQVPLRPM        Sequence 0.7529500    0.040 <= SB\n",
    "   1 HLA-B*07:02      RPQVPLRPM RPQVPLRPM  0  0  0  0  0    RPQVPLRPM        Sequence 0.9877480    0.010 <= SB\n",
    "   1 HLA-B*42:02      RPQVPLRPM RPQVPLRPM  0  0  0  0  0    RPQVPLRPM        Sequence 0.8408470    0.020 <= SB\n",
    "---------------------------------------------------------------------------------------------------------------------------\n",
    "```"
   ],
   "id": "9cad76807edc1ac2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "seq = 'RPQVPLRPM'\n",
    "prob_by_hla, reps = predict_likelihood(model, seq, hla_fp, hla_fp_data, DEVICE)"
   ],
   "id": "ec928dfca5a6415",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('HLA of interest and their probabilities:')\n",
    "print('\\t Binders:')\n",
    "print('HLA-B*07:02:', prob_by_hla['HLA-B07-02'])\n",
    "print('HLA-B*42:01:', prob_by_hla['HLA-B42-01'])\n",
    "print('HLA-B*42:02:', prob_by_hla['HLA-B42-02'])\n",
    "print('HLA-B*81:01:', prob_by_hla['HLA-B81-01'])"
   ],
   "id": "624cb36d0145c3ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "px.bar(x=prob_by_hla.keys(), y=prob_by_hla.values(), range_y=[0, 1])",
   "id": "7f463f106c9e888f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "coords = umap.fit_transform(reps.mean(1))",
   "id": "c3c3901e2cf7538b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "symbol_dict = {'A': 'circle', 'B': 'x', 'C': 'diamond'}\n",
    "size_dict = {'A': 10, 'B': 12, 'C': 12}\n",
    "\n",
    "fig.add_traces(\n",
    "    go.Scatter(\n",
    "        x = coords[:, 0],\n",
    "        y = coords[:, 1],\n",
    "        mode='markers',\n",
    "        marker = dict(\n",
    "            color = list(prob_by_hla.values()),\n",
    "            colorscale='Portland_r',\n",
    "            symbol = [symbol_dict[x.split('-')[1][0]] for x in list(prob_by_hla.keys())],\n",
    "            size = [size_dict[x.split('-')[1][0]] for x in list(prob_by_hla.keys())],\n",
    "            showscale = True,\n",
    "            opacity = [1 if h in ['HLA-B42-01', 'HLA-B42-02', 'HLA-B81-01', 'HLA-B07-02'] else 0.3 for h in prob_by_hla.keys()],\n",
    "            colorbar=dict(\n",
    "                len=0.75,\n",
    "                title_text='binding score',\n",
    "                xanchor=\"right\", x=1.3,\n",
    "                yanchor='bottom', y=0.1,\n",
    "                thickness=20,\n",
    "            ),\n",
    "            line=dict(width=1)\n",
    "        ),\n",
    "        hovertext = [f'name: {n}<br>prob: {p}' for n, p in zip(list(prob_by_hla.keys()), prob_by_hla.values())]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    # showlegend=True,\n",
    "    font={'family': \"Arial\"}, width=800, height=800,\n",
    "    )"
   ],
   "id": "d7379cf548acbddb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Case study 2:\n",
    "\n",
    "Pymm, P., Illing, P., Ramarathinam, S. et al. MHC-I peptides get out of the groove and enable a novel mechanism of HIV-1 escape. Nat Struct Mol Biol 24, 387–394 (2017). https://doi.org/10.1038/nsmb.3381 \n",
    "\n",
    "\n",
    "Structures of HLA-B*57:01 presenting N-terminally extended peptides, including the immunodominant HIV-1 Gag epitope TW10 (TSTLQEQIGW), showed that the N terminus protrudes from the peptide-binding groove. The common escape mutant TSNLQEQIGW bound HLA-B*57:01 canonically, adopting a dramatically different conformation than the TW10 peptide. This affected recognition by killer cell immunoglobulin-like receptor (KIR) 3DL1 expressed on NK cells.\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "HLA allele: HLA-B*57:01\n",
    "\n",
    "- TW10 Peptide: `TSTLQEQIGW`\n",
    "- T3N Peptide:  `TSNLQEQIGW` (Different binding mode. Escapes immune response)\n",
    "\n",
    "\n",
    "Crystals of interest:\n",
    "- 5T6Z: HLA-B*57:01 Pep: TW10\n",
    "- 5T6Z: HLA-B*57:01 Pep: TW10\n",
    "- 5T70: HLA-B*57:01 Pep: T3N\n",
    "- 5V5L: HLA-B*58:01 Pep: TW10\n",
    "24 more pHLA for HLA-B*57:01 (check [here](https://github.com/annadiarov/seq2HLAallele/blob/master/databases/mhc1_pdb/prep_mhc1_pdb_list.csv)) "
   ],
   "id": "43f0a02d34e6db75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "phla_list = [\n",
    "    'HLA-B57-01', # From paper\n",
    "    'HLA-B58-01', # Has crystal with TW10. Should bind with T3N according to BA\n",
    "    'HLA-B58-02', # It's a binder (BA)\n",
    "    'HLA-B57-03', # It's a binder (BA)\n",
    "]\n",
    "seq_list = ['TSTLQEQIGW', 'TSNLQEQIGW']\n",
    "pdb_data_file = '/home/bsccns/epfl/seq2HLAallele/databases/mhc1_pdb/prep_mhc1_pdb_list.csv'\n",
    "\n",
    "selected_fp, selected_fp_data = select_pool_hla_fp(phla_list, hla_fp, hla_fp_data)"
   ],
   "id": "7ff0ea0b5d662115",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pdb_data = pd.read_csv(pdb_data_file)\n",
    "hla_b5701_uniq_pep = pdb_data[pdb_data.MHC_Name == 'B*57:01'].Epitope.unique()\n",
    "hla_b5801_uniq_pep = pdb_data[pdb_data.MHC_Name == 'B*58:01'].Epitope.unique()\n",
    "\n",
    "print('HLA-B57-01 unique peptides with PDB:', len(hla_b5701_uniq_pep))\n",
    "print('HLA-B58-01 unique peptides with PDB:', len(hla_b5801_uniq_pep))\n",
    "print('Common peptides:', set(hla_b5701_uniq_pep).intersection(set(hla_b5801_uniq_pep)))"
   ],
   "id": "5b11262d56844fe7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "prob_by_hla, reps, attns_dict = predict_likelihood_several_peptides(model, hla_b5701_uniq_pep, selected_fp, selected_fp_data, DEVICE, save_attn=True)",
   "id": "438aad09f58b34a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "umap = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    ")\n",
    "\n",
    "coords = umap.fit_transform(reps.mean(1))"
   ],
   "id": "f06a32ce0a06b8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "symbol_dict = {'A': 'circle', 'B': 'x', 'C': 'diamond'}\n",
    "size_dict = {'A': 10, 'B': 12, 'C': 12}\n",
    "\n",
    "fig.add_traces(\n",
    "    go.Scatter(\n",
    "        x = coords[:, 0],\n",
    "        y = coords[:, 1],\n",
    "        mode='markers',\n",
    "        marker = dict(\n",
    "            color = list(prob_by_hla.values()),\n",
    "            colorscale='Portland_r',\n",
    "            symbol = [symbol_dict[x.split('-')[1][0]] for x in list(prob_by_hla.keys())],\n",
    "            size = [size_dict[x.split('-')[1][0]] for x in list(prob_by_hla.keys())],\n",
    "            showscale = True,\n",
    "            opacity = [1 if seq_list[0] in h or seq_list[1] in h else 0.3 for h in prob_by_hla.keys()],\n",
    "            colorbar=dict(\n",
    "                len=0.75,\n",
    "                title_text='binding score',\n",
    "                xanchor=\"right\", x=1.3,\n",
    "                yanchor='bottom', y=0.1,\n",
    "                thickness=20,\n",
    "            ),\n",
    "            line=dict(width=1)\n",
    "        ),\n",
    "        hovertext = [f'name: {n}<br>prob: {p}' for n, p in zip(list(prob_by_hla.keys()), prob_by_hla.values())]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    font={'family': \"Arial\"}, width=800, height=800,\n",
    "    xaxis_title='UMAP 1',\n",
    "    yaxis_title='UMAP 2',\n",
    "\n",
    "    )"
   ],
   "id": "274787f49e87b2c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Case study 3:\n",
    "\n",
    "PRIME2 immunogenic peptides."
   ],
   "id": "488a11ea1a638ee6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prime2_data_file = os.path.join(PROCESSED_DATA, 'immunogenicity', 'PRIME', 'train_PRIME2_2023_peptides_hla_ABC_with_BalancedSplits_remove2HLA.csv')\n",
    "prime2_data = pd.read_csv(prime2_data_file)\n",
    "prime2_data.head()"
   ],
   "id": "945a0c9d183bc0f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TEST_ON_IMMUNOGENIC_ONLY = False # If True, only immunogenic peptides will be used for testing\n",
    "\n",
    "if 'ManSplit' in exp_name:\n",
    "    test_split = exp_name.split('ManSplit')[1].split('_')[1]\n",
    "    test_imuno_data = prime2_data[prime2_data['split'] == int(test_split)]\n",
    "    logger.info(f'Test split: {test_split}. Using {len(test_imuno_data)} peptides as test data.')\n",
    "else:\n",
    "    test_imuno_data = prime2_data\n",
    "    logger.info('Using all data as test data.')\n",
    "    \n",
    "if TEST_ON_IMMUNOGENIC_ONLY:\n",
    "    logger.warn('Testing only on immunogenic peptides.')\n",
    "    test_imuno_data = test_imuno_data[test_imuno_data.label == 1]\n",
    "    logger.info(f'Test data has {len(test_imuno_data)} immunogenic peptides, {len(test_imuno_data.hla_allele.unique())} unique HLA alleles.')\n",
    "else:\n",
    "    logger.info(f'Test data has {len(test_imuno_data)} peptides, {len(test_imuno_data.hla_allele.unique())} unique HLA alleles. There are {len(test_imuno_data[test_imuno_data.label == 1])} immunogenic pairs and {len(test_imuno_data[test_imuno_data.label == 0])} non-immunogenic pairs.')"
   ],
   "id": "43297e059f57961a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "USE_AUGMENTED_HLA_DATA = False  # If the FP provided are augmented\n",
    "USE_ALL_AUGMENTED_HLA_FP_DATA = False # Whether to use all augmented FP or just pick one randomly\n",
    "\n",
    "hla_fp_dict = {hla: torch.Tensor(hla_fp[idx]) for hla, idx in hla_fp_data.items()}\n",
    "\n",
    "test_immuno_dataset = pHLADataset(\n",
    "            peptide_seq_arr=test_imuno_data['peptide'].values,\n",
    "            hla_names_arr=test_imuno_data['hla_allele'].values,\n",
    "            hla_fp_dict=hla_fp_dict,\n",
    "            labels=test_imuno_data['label'].values,\n",
    "            has_augmented_hla=USE_AUGMENTED_HLA_DATA,\n",
    "            use_all_augmented_data=USE_ALL_AUGMENTED_HLA_FP_DATA\n",
    "        )"
   ],
   "id": "b2b223aa2c793ac3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_immuno_loader = torch.utils.data.DataLoader(test_immuno_dataset, batch_size=64, shuffle=False, num_workers=4)",
   "id": "5a004b8674fbf963",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# all_probs, reps, attns_dict = predict_likelihood_from_dataloader(model, test_immuno_loader, DEVICE, save_attn=True)\n",
    "all_probs, reps = predict_likelihood_from_dataloader(model, test_immuno_loader, DEVICE, save_attn=False)"
   ],
   "id": "99a2c97abb22e790",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for attn_type, attn_arr in attns_dict.items():\n",
    "    if attn_type.startswith('filip'):\n",
    "        print(f'{attn_type} has {len(attn_arr)} BatchSize each batch with shape {attn_arr[0].shape}. So the object shape is {attn_arr.shape}')        \n",
    "    else:\n",
    "        print(f'{attn_type} has {len(attn_arr)} layers each with shape {attn_arr[0].shape} each') "
   ],
   "id": "d167fee55a930b77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "umap = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    ")\n",
    "\n",
    "coords = umap.fit_transform(reps.mean(1))\n"
   ],
   "id": "b976bc16b450655f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "symbol_dict = {'A': 'circle', 'B': 'x', 'C': 'diamond'}\n",
    "size_dict = {'A': 10, 'B': 12, 'C': 12}\n",
    "\n",
    "fig.add_traces(\n",
    "    go.Scatter(\n",
    "        x = coords[:, 0],\n",
    "        y = coords[:, 1],\n",
    "        mode='markers',\n",
    "        marker = dict(\n",
    "            color = list(all_probs),\n",
    "            colorscale='Portland_r',\n",
    "            symbol = [symbol_dict[hla.split('-')[1][0]] for hla in test_imuno_data.hla_allele],\n",
    "            size = [size_dict[hla.split('-')[1][0]] for hla in test_imuno_data.hla_allele],\n",
    "            showscale = True,\n",
    "            opacity = [1 if label == 1 else 0.3 for label in test_imuno_data.label],\n",
    "            colorbar=dict(\n",
    "                len=0.75,\n",
    "                title_text='binding score',\n",
    "                xanchor=\"right\", x=1.3,\n",
    "                yanchor='bottom', y=0.1,\n",
    "                thickness=20,\n",
    "            ),\n",
    "            line=dict(width=1)\n",
    "        ),\n",
    "        hovertext = [f'label: {label}<br>name: {hla}-{pep}<br>prob: {prob}' for label, prob, pep, hla in zip(list(test_imuno_data.label),all_probs, list(test_imuno_data.peptide), list(test_imuno_data.hla_allele))]\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    template='simple_white',\n",
    "    # showlegend=True,\n",
    "    font={'family': \"Arial\"}, width=800, height=800,\n",
    "    xaxis_title='UMAP 1',\n",
    "    yaxis_title='UMAP 2',\n",
    "\n",
    "    )"
   ],
   "id": "e2fcb8bdfd2726ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3bb410ce947ec655",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
