{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Peptide encoding to low-dim vector\n",
    "\n",
    "Encoding of epitopes using TEIM paper autoencoder\n",
    "\n",
    "[![DOI:10.1016/j.immuni.2023.09.002](https://zenodo.org/badge/DOI/10.1007/978-3-319-76207-4_15.svg)](https://doi.org/10.1038/s42256-023-00634-4)\n",
    "\n",
    "\n",
    "To run the encoding, the following code MUST be copied into a file called `data_process.py` in the same dir that this notebook:\n",
    "\n",
    "```\n",
    "from Bio.Align import substitution_matrices\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append('.')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def GetBlosumMat(residues_list):\n",
    "    n_residues = len(residues_list)  # the number of amino acids _ 'X'\n",
    "    blosum62_mat = np.zeros([n_residues, n_residues])  # plus 1 for gap\n",
    "    bl_dict = substitution_matrices.load('BLOSUM62')\n",
    "    for pair, score in bl_dict.items():\n",
    "        if (pair[0] not in residues_list) or (pair[1] not in residues_list):  # special residues not considered here\n",
    "            continue\n",
    "        idx_pair0 = residues_list.index(pair[0])  # index of residues\n",
    "        idx_pair1 = residues_list.index(pair[1])\n",
    "        blosum62_mat[idx_pair0, idx_pair1] = score\n",
    "        blosum62_mat[idx_pair1, idx_pair0] = score\n",
    "    return blosum62_mat\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self,):\n",
    "        self.res_all = ['G', 'A', 'V', 'L', 'I', 'F', 'W', 'Y', 'D', 'N',\n",
    "                     'E', 'K', 'Q', 'M', 'S', 'T', 'C', 'P', 'H', 'R'] #+ ['X'] #BJZOU\n",
    "        self.tokens = ['-'] + self.res_all # '-' for padding encoding\n",
    "\n",
    "    def tokenize(self, index): # int 2 str\n",
    "        return self.tokens[index]\n",
    "\n",
    "    def id(self, token): # str 2 int\n",
    "        try:\n",
    "            return self.tokens.index(token.upper())\n",
    "        except ValueError:\n",
    "            print('Error letter in the sequences:', token)\n",
    "            if str.isalpha(token):\n",
    "                return self.tokens.index('X')\n",
    "\n",
    "    def tokenize_list(self, seq):\n",
    "        return [self.tokenize(i) for i in seq]\n",
    "\n",
    "    def id_list(self, seq):\n",
    "        return [self.id(s) for s in seq]\n",
    "\n",
    "    def embedding_mat(self):\n",
    "        blosum62 = GetBlosumMat(self.res_all)\n",
    "        mat = np.eye(len(self.tokens))\n",
    "        mat[1:len(self.res_all) + 1, 1:len(self.res_all) + 1] = blosum62\n",
    "        return mat\n",
    "```\n"
   ],
   "id": "d38a722a4ecb6fe4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:40:24.769731Z",
     "start_time": "2024-04-14T18:40:24.079320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CODE FROM TEIM PAPER\n",
    "#     Path on GitHub Repo:     TEIM/scripts/data_process.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    \n",
    "class View(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self, input):\n",
    "        shape = [input.shape[0]] + list(self.shape)\n",
    "        return input.view(*shape)\n",
    "    \n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "        tokenizer,\n",
    "        dim_hid,\n",
    "        len_seq,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        embedding = tokenizer.embedding_mat()\n",
    "        vocab_size, dim_emb = embedding.shape\n",
    "        self.embedding_module = nn.Embedding.from_pretrained(torch.FloatTensor(embedding), padding_idx=0, )\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_hid, 3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(dim_hid, dim_hid, 3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.seq2vec = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(len_seq * dim_hid, dim_hid),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.vec2seq = nn.Sequential(\n",
    "            nn.Linear(dim_hid, len_seq * dim_hid),\n",
    "            nn.ReLU(),\n",
    "            View(dim_hid, len_seq)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(dim_hid, dim_hid, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(dim_hid, dim_hid, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out_layer = nn.Linear(dim_hid, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.long()\n",
    "        seq_emb = self.embedding_module(inputs)\n",
    "        \n",
    "        seq_enc = self.encoder(seq_emb.transpose(1, 2))\n",
    "        vec = self.seq2vec(seq_enc)\n",
    "        seq_repr = self.vec2seq(vec)\n",
    "        indices = None\n",
    "        seq_dec = self.decoder(seq_repr)\n",
    "        out = self.out_layer(seq_dec.transpose(1, 2))\n",
    "        return out, seq_enc, vec, indices\n",
    "\n",
    "\n",
    "def load_ae_model(tokenizer, path='./epi_ae.ckpt',):\n",
    "    # tokenizer = Tokenizer()\n",
    "    ## load model\n",
    "    model_args = dict(\n",
    "        tokenizer = tokenizer,\n",
    "        dim_hid = 32,\n",
    "        len_seq = 12,\n",
    "    )\n",
    "    model = AutoEncoder(**model_args)\n",
    "    model.eval()\n",
    "\n",
    "    ## load weights\n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    state_dict = {k[6:]:v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "class PretrainedEncoder:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.ae_model = load_ae_model(tokenizer)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def encode_pretrained_epi(self, epi_seqs):\n",
    "        enc = self.infer(epi_seqs)\n",
    "        enc_vec = enc[2]\n",
    "        enc_seq = enc[-1]\n",
    "        return enc_seq, enc_vec\n",
    "    \n",
    "    def infer(self, seqs):\n",
    "        # # seqs encoding\n",
    "        n_seqs = len(seqs)\n",
    "        len_seqs = [len(seq) for seq in seqs]\n",
    "        assert (np.max(len_seqs) <= 12) and (np.min(len_seqs)>=8), ValueError('Lengths of epitopes must be within [8, 12]')\n",
    "        encoding = np.zeros([n_seqs, 12], dtype='int32')\n",
    "        for i, seq in enumerate(seqs):\n",
    "            len_seq = len_seqs[i]\n",
    "            if len_seq == 8:\n",
    "                encoding[i, 2:len_seq+2] = self.tokenizer.id_list(seq)\n",
    "            elif (len_seq == 9) or (len_seq == 10):\n",
    "                encoding[i, 1:len_seq+1] = self.tokenizer.id_list(seq)\n",
    "            else:\n",
    "                encoding[i, :len_seq] = self.tokenizer.id_list(seq)\n",
    "        # # pretrained ae features\n",
    "        inputs = torch.from_numpy(encoding)\n",
    "        out, seq_enc, vec, indices = self.ae_model(inputs)\n",
    "        out = np.argmax(out.detach().cpu().numpy(), -1)\n",
    "        return [\n",
    "            out,\n",
    "            seq_enc.detach().cpu().numpy(),\n",
    "            vec.detach().cpu().numpy(),\n",
    "            indices,\n",
    "            encoding\n",
    "        ]\n",
    "    "
   ],
   "id": "23b456685f5dca0",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:40:25.205993Z",
     "start_time": "2024-04-14T18:40:24.770811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manually load Tokenizer from their params\n",
    "tokenizer = torch.load('base_model.ckpt', map_location=torch.device('cpu'))['hyper_parameters']['model_args']['tokenizer']\n",
    "epi_encoder = PretrainedEncoder(tokenizer)"
   ],
   "id": "5a7941c5d337eca9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:40:25.374758Z",
     "start_time": "2024-04-14T18:40:25.206671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_train_file = '/home/bsccns/Documents/PhD/neoantigen_predictor/nimbus/data/raw/pHLA_binding/NetMHCpan_train/c000_ba'\n",
    "df = pd.read_csv(sample_train_file, sep=' ', header=None)\n",
    "seqs_epi_raw = df[0].values.tolist()"
   ],
   "id": "906fc01db6fed475",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:40:25.381135Z",
     "start_time": "2024-04-14T18:40:25.375554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter epitopes to 8 to 12 AA\n",
    "seqs_epi = []\n",
    "n_larger = 0\n",
    "for s in seqs_epi_raw:\n",
    "    if len(s) < 13:\n",
    "        seqs_epi.append(s)\n",
    "    else:\n",
    "        n_larger +=1\n",
    "        \n",
    "print(f'{n_larger} peptides out of {len(seqs_epi_raw)} were longer than 12 AA')"
   ],
   "id": "4c52198116d75ce2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 peptides out of 41206 were longer than 12 AA\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:40:25.822833Z",
     "start_time": "2024-04-14T18:40:25.382015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seqs_epi = ['AAAAAAAA']\n",
    "encoding_epi, epi_vec = epi_encoder.encode_pretrained_epi(seqs_epi)\n",
    "\n",
    "epi_vec[:5]"
   ],
   "id": "bafa5c818a9b56ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.237492  , 2.5128953 , 3.5028358 , 1.0474035 , 5.3211064 ,\n",
       "        2.8364499 , 0.        , 1.3840181 , 3.142711  , 2.7802851 ,\n",
       "        3.1927416 , 3.7346904 , 1.4508824 , 2.1306121 , 1.5529792 ,\n",
       "        1.6950285 , 3.5080004 , 2.1665826 , 1.6668513 , 1.2255855 ,\n",
       "        1.2941527 , 2.1354334 , 5.0765424 , 2.4932017 , 1.3577513 ,\n",
       "        2.8210332 , 3.274586  , 2.3020668 , 2.0123103 , 2.1274827 ,\n",
       "        3.5270824 , 1.6267327 ],\n",
       "       [4.237492  , 2.5128953 , 3.5028358 , 1.0474035 , 5.3211064 ,\n",
       "        2.8364499 , 0.        , 1.3840181 , 3.142711  , 2.7802851 ,\n",
       "        3.1927416 , 3.7346904 , 1.4508824 , 2.1306121 , 1.5529792 ,\n",
       "        1.6950285 , 3.5080004 , 2.1665826 , 1.6668513 , 1.2255855 ,\n",
       "        1.2941527 , 2.1354334 , 5.0765424 , 2.4932017 , 1.3577513 ,\n",
       "        2.8210332 , 3.274586  , 2.3020668 , 2.0123103 , 2.1274827 ,\n",
       "        3.5270824 , 1.6267327 ],\n",
       "       [5.2254972 , 2.711007  , 3.3354301 , 1.0361304 , 5.320385  ,\n",
       "        1.7822485 , 0.        , 0.63811386, 3.4599936 , 2.2775054 ,\n",
       "        1.665637  , 2.998255  , 1.90144   , 2.5897293 , 1.3478482 ,\n",
       "        2.9703555 , 2.5355368 , 2.9074516 , 2.066756  , 0.91151166,\n",
       "        1.8872628 , 2.537565  , 6.202757  , 1.9328605 , 2.9389982 ,\n",
       "        4.5423026 , 2.3136249 , 2.4316373 , 2.6535852 , 3.4235642 ,\n",
       "        3.5005307 , 1.4037695 ],\n",
       "       [5.2254972 , 2.711007  , 3.3354301 , 1.0361304 , 5.320385  ,\n",
       "        1.7822485 , 0.        , 0.63811386, 3.4599936 , 2.2775054 ,\n",
       "        1.665637  , 2.998255  , 1.90144   , 2.5897293 , 1.3478482 ,\n",
       "        2.9703555 , 2.5355368 , 2.9074516 , 2.066756  , 0.91151166,\n",
       "        1.8872628 , 2.537565  , 6.202757  , 1.9328605 , 2.9389982 ,\n",
       "        4.5423026 , 2.3136249 , 2.4316373 , 2.6535852 , 3.4235642 ,\n",
       "        3.5005307 , 1.4037695 ],\n",
       "       [5.2254972 , 2.711007  , 3.3354301 , 1.0361304 , 5.320385  ,\n",
       "        1.7822485 , 0.        , 0.63811386, 3.4599936 , 2.2775054 ,\n",
       "        1.665637  , 2.998255  , 1.90144   , 2.5897293 , 1.3478482 ,\n",
       "        2.9703555 , 2.5355368 , 2.9074516 , 2.066756  , 0.91151166,\n",
       "        1.8872628 , 2.537565  , 6.202757  , 1.9328605 , 2.9389982 ,\n",
       "        4.5423026 , 2.3136249 , 2.4316373 , 2.6535852 , 3.4235642 ,\n",
       "        3.5005307 , 1.4037695 ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:40:25.824814Z",
     "start_time": "2024-04-14T18:40:25.823470Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "65800a9d7b25c1d6",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
