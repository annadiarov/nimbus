{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Peptide encoding to low-dim vector\n",
    "\n",
    "Encoding of epitopes using TEIM paper autoencoder\n",
    "\n",
    "[![DOI:10.1016/j.immuni.2023.09.002](https://zenodo.org/badge/DOI/10.1007/978-3-319-76207-4_15.svg)](https://doi.org/10.1038/s42256-023-00634-4)\n"
   ],
   "id": "d38a722a4ecb6fe4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:01:42.491987Z",
     "start_time": "2024-04-14T18:01:41.945143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# CODE FROM TEIM PAPER\n",
    "#     Path on GitHub Repo:     TEIM/scripts/data_process.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from Bio.Align import substitution_matrices\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def GetBlosumMat(residues_list):\n",
    "    n_residues = len(residues_list)  # the number of amino acids _ 'X'\n",
    "    blosum62_mat = np.zeros([n_residues, n_residues])  # plus 1 for gap\n",
    "    bl_dict = substitution_matrices.load('BLOSUM62')\n",
    "    for pair, score in bl_dict.items():\n",
    "        if (pair[0] not in residues_list) or (pair[1] not in residues_list):  # special residues not considered here\n",
    "            continue\n",
    "        idx_pair0 = residues_list.index(pair[0])  # index of residues\n",
    "        idx_pair1 = residues_list.index(pair[1])\n",
    "        blosum62_mat[idx_pair0, idx_pair1] = score\n",
    "        blosum62_mat[idx_pair1, idx_pair0] = score\n",
    "    return blosum62_mat\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    def __init__(self,):\n",
    "        self.res_all = ['G', 'A', 'V', 'L', 'I', 'F', 'W', 'Y', 'D', 'N',\n",
    "                     'E', 'K', 'Q', 'M', 'S', 'T', 'C', 'P', 'H', 'R'] #+ ['X'] #BJZOU\n",
    "        self.tokens = ['-'] + self.res_all # '-' for padding encoding\n",
    "\n",
    "    def tokenize(self, index): # int 2 str\n",
    "        return self.tokens[index]\n",
    "\n",
    "    def id(self, token): # str 2 int\n",
    "        try:\n",
    "            return self.tokens.index(token.upper())\n",
    "        except ValueError:\n",
    "            print('Error letter in the sequences:', token)\n",
    "            if str.isalpha(token):\n",
    "                return self.tokens.index('X')\n",
    "\n",
    "    def tokenize_list(self, seq):\n",
    "        return [self.tokenize(i) for i in seq]\n",
    "\n",
    "    def id_list(self, seq):\n",
    "        return [self.id(s) for s in seq]\n",
    "\n",
    "    def embedding_mat(self):\n",
    "        blosum62 = GetBlosumMat(self.res_all)\n",
    "        mat = np.eye(len(self.tokens))\n",
    "        mat[1:len(self.res_all) + 1, 1:len(self.res_all) + 1] = blosum62\n",
    "        return mat\n",
    "    \n",
    "class View(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self, input):\n",
    "        shape = [input.shape[0]] + list(self.shape)\n",
    "        return input.view(*shape)\n",
    "    \n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, \n",
    "        tokenizer,\n",
    "        dim_hid,\n",
    "        len_seq,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        embedding = tokenizer.embedding_mat()\n",
    "        vocab_size, dim_emb = embedding.shape\n",
    "        self.embedding_module = nn.Embedding.from_pretrained(torch.FloatTensor(embedding), padding_idx=0, )\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(dim_emb, dim_hid, 3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(dim_hid, dim_hid, 3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.seq2vec = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(len_seq * dim_hid, dim_hid),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.vec2seq = nn.Sequential(\n",
    "            nn.Linear(dim_hid, len_seq * dim_hid),\n",
    "            nn.ReLU(),\n",
    "            View(dim_hid, len_seq)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(dim_hid, dim_hid, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(dim_hid, dim_hid, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(dim_hid),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out_layer = nn.Linear(dim_hid, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.long()\n",
    "        seq_emb = self.embedding_module(inputs)\n",
    "        \n",
    "        seq_enc = self.encoder(seq_emb.transpose(1, 2))\n",
    "        vec = self.seq2vec(seq_enc)\n",
    "        seq_repr = self.vec2seq(vec)\n",
    "        indices = None\n",
    "        seq_dec = self.decoder(seq_repr)\n",
    "        out = self.out_layer(seq_dec.transpose(1, 2))\n",
    "        return out, seq_enc, vec, indices\n",
    "\n",
    "\n",
    "def load_ae_model(tokenizer, path='./epi_ae.ckpt',):\n",
    "    # tokenizer = Tokenizer()\n",
    "    ## load model\n",
    "    model_args = dict(\n",
    "        tokenizer = tokenizer,\n",
    "        dim_hid = 32,\n",
    "        len_seq = 12,\n",
    "    )\n",
    "    model = AutoEncoder(**model_args)\n",
    "    model.eval()\n",
    "\n",
    "    ## load weights\n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    state_dict = {k[6:]:v for k, v in state_dict.items()}\n",
    "    model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "class PretrainedEncoder:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.ae_model = load_ae_model(tokenizer)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def encode_pretrained_epi(self, epi_seqs):\n",
    "        enc = self.infer(epi_seqs)\n",
    "        enc_vec = enc[2]\n",
    "        enc_seq = enc[-1]\n",
    "        return enc_seq, enc_vec\n",
    "    \n",
    "    def infer(self, seqs):\n",
    "        # # seqs encoding\n",
    "        n_seqs = len(seqs)\n",
    "        len_seqs = [len(seq) for seq in seqs]\n",
    "        assert (np.max(len_seqs) <= 12) and (np.min(len_seqs)>=8), ValueError('Lengths of epitopes must be within [8, 12]')\n",
    "        encoding = np.zeros([n_seqs, 12], dtype='int32')\n",
    "        for i, seq in enumerate(seqs):\n",
    "            len_seq = len_seqs[i]\n",
    "            if len_seq == 8:\n",
    "                encoding[i, 2:len_seq+2] = self.tokenizer.id_list(seq)\n",
    "            elif (len_seq == 9) or (len_seq == 10):\n",
    "                encoding[i, 1:len_seq+1] = self.tokenizer.id_list(seq)\n",
    "            else:\n",
    "                encoding[i, :len_seq] = self.tokenizer.id_list(seq)\n",
    "        # # pretrained ae features\n",
    "        inputs = torch.from_numpy(encoding)\n",
    "        out, seq_enc, vec, indices = self.ae_model(inputs)\n",
    "        out = np.argmax(out.detach().cpu().numpy(), -1)\n",
    "        return [\n",
    "            out,\n",
    "            seq_enc.detach().cpu().numpy(),\n",
    "            vec.detach().cpu().numpy(),\n",
    "            indices,\n",
    "            encoding\n",
    "        ]\n",
    "    "
   ],
   "id": "23b456685f5dca0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:19:04.062346Z",
     "start_time": "2024-04-14T18:19:04.043823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Manually load Tokenizer from their params\n",
    "tokenizer = torch.load('base_model.ckpt', map_location=torch.device('cpu'))['hyper_parameters']['model_args']['tokenizer']\n",
    "epi_encoder = PretrainedEncoder(tokenizer)"
   ],
   "id": "5a7941c5d337eca9",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:13:56.177384Z",
     "start_time": "2024-04-14T18:13:56.163505Z"
    }
   },
   "cell_type": "code",
   "source": "torch.load('base_model.ckpt', map_location=torch.device('cpu'))['hyper_parameters'].keys()",
   "id": "efb170d558ffb176",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_mode', 'model_args', 'lr', 'weight_decay'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:17:03.676215Z",
     "start_time": "2024-04-14T18:17:03.664719Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = torch.load('base_model.ckpt', map_location=torch.device('cpu'))['hyper_parameters']['model_args']['tokenizer']\n",
   "id": "4fc59cb895a39114",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:17:08.747146Z",
     "start_time": "2024-04-14T18:17:08.727668Z"
    }
   },
   "cell_type": "code",
   "source": "epi_encoder = PretrainedEncoder(tokenizer)\n",
   "id": "175665d75dd6ab9c",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:25:21.411964Z",
     "start_time": "2024-04-14T18:25:21.390283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "sample_train_file = '/home/bsccns/Documents/PhD/neoantigen_predictor/nimbus/data/raw/pHLA_binding/NetMHCpan_train/c000_ba'\n",
    "df = pd.read_csv(sample_train_file, sep=' ', header=None)\n",
    "seqs_epi_raw = df[0].values.tolist()"
   ],
   "id": "906fc01db6fed475",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:26:49.172675Z",
     "start_time": "2024-04-14T18:26:49.165524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Filter epitopes to 8 to 12 AA\n",
    "seqs_epi = []\n",
    "n_larger = 0\n",
    "for s in seqs_epi_raw:\n",
    "    if len(s) < 13:\n",
    "        seqs_epi.append(s)\n",
    "    else:\n",
    "        n_larger +=1\n",
    "        \n",
    "print(f'{n_larger} peptides out of {len(seqs_epi_raw)} were longer than 12 AA')"
   ],
   "id": "4c52198116d75ce2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 peptides out of 41206 were longer than 12 AA\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:25:58.720078Z",
     "start_time": "2024-04-14T18:25:58.210654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seqs_epi = ['AAAAAAAA']\n",
    "encoding_epi, epi_vec = epi_encoder.encode_pretrained_epi(seqs_epi)\n",
    "\n",
    "epi_vec"
   ],
   "id": "bafa5c818a9b56ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.237492  , 2.5128953 , 3.5028358 , ..., 2.1274827 , 3.5270824 ,\n",
       "        1.6267327 ],\n",
       "       [4.237492  , 2.5128953 , 3.5028358 , ..., 2.1274827 , 3.5270824 ,\n",
       "        1.6267327 ],\n",
       "       [5.2254972 , 2.711007  , 3.3354301 , ..., 3.4235642 , 3.5005307 ,\n",
       "        1.4037695 ],\n",
       "       ...,\n",
       "       [4.203428  , 2.490598  , 4.264105  , ..., 1.4114679 , 2.5099704 ,\n",
       "        0.59674186],\n",
       "       [5.5927343 , 2.632871  , 3.8631663 , ..., 4.6586323 , 4.1849556 ,\n",
       "        1.4040419 ],\n",
       "       [5.0907674 , 2.8708143 , 3.5583603 , ..., 2.0058498 , 3.3439643 ,\n",
       "        1.2341462 ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:23:07.485831Z",
     "start_time": "2024-04-14T18:23:07.471174Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ca73e2de20cfa289",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m epi_vec\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "65800a9d7b25c1d6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
