{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Get random peptides\n",
    "\n",
    "Similarly to NetMHCpan and MixMHCpred, we will sample random peptides from the human proteome to use them for ranking.\n",
    "\n",
    "We will generate 100,000 peptides for each peptide length in between 8 and 15.\n",
    "\n",
    "To accomplish this task, we'll need to follow these steps for each peptide length:\n",
    "\n",
    "- Parse the human proteome file to extract all possible peptides of lengths 8 to 15.\n",
    "- Predict which of these peptides are likely to be cut by the proteasome.\n",
    "- Randomly sample 100,000 peptides for each length, ensuring no duplicates.\n",
    "- Save the sampled peptides to a file.\n",
    "\n",
    "Randomly sampled peptides data will be saved in the `processed/random_proteasome_cleaved_peptides` directory. \n",
    "\n",
    "#### Details\n",
    "\n",
    "- We downloaded the human proteome from [UniProt](https://www.uniprot.org/proteomes/UP000005640] ) and saved it in the `data/raw/human_proteome` directory. We downloaded only reviewed (Swiss-Prot) canonical proteins (20,420)\n",
    "- We will use NetChop to predict proteasome cleavage sites in the human proteome. We will save the cleaved peptides in the `data/interim/cleaved_human_proteome` directory. We downloaded NetChop from the [official website](https://services.healthtech.dtu.dk/services/NetChop-3.1/). Note that it is not available for commercial use."
   ],
   "id": "e0d5ee31ff394c45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T18:57:26.968586Z",
     "start_time": "2024-06-14T18:57:26.800330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO"
   ],
   "id": "9883a9209023f67c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T18:57:26.972969Z",
     "start_time": "2024-06-14T18:57:26.969953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = '../data'\n",
    "proteome_fasta_file = os.path.join(DATA_DIR, 'raw', 'human_proteome', 'uniprotkb_proteome_UP000005640_AND_revi_2024_06_14.fasta')\n",
    "cleaved_human_proteome_dir = os.path.join(DATA_DIR, 'interim', 'cleaved_human_proteome')\n",
    "processed_random_peptides_dir = os.path.join(DATA_DIR, 'processed', 'random_proteasome_cleaved_peptides')\n",
    "NETCHOP_PREDICTOR = '/home/bsccns/Documents/PhD/software/netchop-3.1/netchop'\n",
    "N_RND_PEPTIDES = 100000\n",
    "peptide_length = [8, 9, 10, 11, 12, 13, 14, 15]"
   ],
   "id": "c452514dc2db04d1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T18:57:26.991589Z",
     "start_time": "2024-06-14T18:57:26.973803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_netchop(\n",
    "        protein_sequence: str,\n",
    "        path_to_netchop: str\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Run NetChop to predict cleavage sites in a protein sequence.\n",
    "    :param protein_sequence: str\n",
    "        Aminoacid sequence of a single protein \n",
    "    :param path_to_netchop: str\n",
    "        Path to the NetChop executable\n",
    "    :return: \n",
    "        List of cleavage sites predicted by NetChop. A cleaved peptide will\n",
    "        start after the cleavage site.\n",
    "    \"\"\"\n",
    "    # Create a temporary file to write the protein sequence in FASTA format\n",
    "    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.fasta') as temp_fasta:\n",
    "        temp_fasta.write(\">protein_sequence\\n\")\n",
    "        temp_fasta.write(protein_sequence)\n",
    "        fasta_file_path = temp_fasta.name\n",
    "    \n",
    "    try:\n",
    "        # Run NetChop\n",
    "        result = subprocess.run([path_to_netchop, fasta_file_path], capture_output=True, text=True)\n",
    "        output = result.stdout\n",
    "        \n",
    "        # Parse the output\n",
    "        cleavage_positions = []\n",
    "        parsing = False  # Initialize the parsing variable\n",
    "        for line in output.split('\\n'):\n",
    "            if line.startswith('--------------------------------------'):\n",
    "                # Start parsing after the header\n",
    "                parsing = True\n",
    "            elif parsing:\n",
    "                if line.strip() == '':\n",
    "                    # Stop parsing at the end of the relevant section\n",
    "                    break\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4 and parts[2] == 'S':\n",
    "                    cleavage_positions.append(int(parts[0]))\n",
    "                    \n",
    "        return cleavage_positions\n",
    "    \n",
    "    finally:\n",
    "        # Clean up the temporary file\n",
    "        os.remove(fasta_file_path)\n",
    "        \n",
    "def find_cleavable_peptides(\n",
    "        fasta_file: str, \n",
    "        peptide_lengths: list,\n",
    "        path_to_netchop: str\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Find peptides that can be cleaved by the proteasome according NetChop given protein sequences.\n",
    "    :param fasta_file: str\n",
    "        Path to the FASTA file containing the protein sequences\n",
    "    :param peptide_lengths: list\n",
    "        List of peptide lengths to consider\n",
    "    :param path_to_netchop: str\n",
    "        Path to the NetChop executable\n",
    "    :return: dict\n",
    "        Dictionary containing a list of cleavable peptides for each peptide length\n",
    "    \"\"\"\n",
    "    cleavable_peptides = {length: [] for length in peptide_lengths}\n",
    "    for record in tqdm(SeqIO.parse(fasta_file, \"fasta\"), total=len(list(SeqIO.parse(fasta_file, \"fasta\")))):\n",
    "        protein_sequence = str(record.seq)\n",
    "        cleavage_sites = run_netchop(protein_sequence, path_to_netchop)\n",
    "\n",
    "        for pos in cleavage_sites:\n",
    "            # Ensure the peptide is within the bounds of the sequence\n",
    "            for length in peptide_lengths:\n",
    "                if pos + length <= len(protein_sequence):\n",
    "                    peptide = protein_sequence[pos:pos+length]\n",
    "                    cleavable_peptides[length].append(peptide)\n",
    "    # This will return the list of peptides with duplicates\n",
    "    return cleavable_peptides\n"
   ],
   "id": "a364d8d8b0d43acc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T19:36:00.102897Z",
     "start_time": "2024-06-14T18:57:26.992481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cleavable_peptides = find_cleavable_peptides(proteome_fasta_file, peptide_length, NETCHOP_PREDICTOR)\n",
    "\n",
    "for length, peptides in cleavable_peptides.items():\n",
    "    with open(os.path.join(cleaved_human_proteome_dir, f'cleavable_peptides_length_{length}.txt'), 'w') as f:\n",
    "        for peptide in peptides:\n",
    "            f.write(f'{peptide}\\n')"
   ],
   "id": "3b671e051b1c60b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20420/20420 [38:29<00:00,  8.84it/s] \n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T22:20:13.090350Z",
     "start_time": "2024-06-14T22:19:57.287858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save data withou duplicates\n",
    "for length in peptide_length:\n",
    "    with open(os.path.join(cleaved_human_proteome_dir, f'cleavable_peptides_length_{length}.txt'), 'r') as f:\n",
    "        peptides = f.readlines()\n",
    "        peptides = [peptide.strip() for peptide in peptides]\n",
    "        peptides = list(set(peptides))\n",
    "        \n",
    "    with open(os.path.join(cleaved_human_proteome_dir, f'cleavable_peptides_length_{length}_no_duplicates.txt'), 'w') as f:\n",
    "        for peptide in peptides:\n",
    "            f.write(f'{peptide}\\n')"
   ],
   "id": "e7bdac6a155e1b63",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-14T22:21:19.176976Z",
     "start_time": "2024-06-14T22:21:12.023032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample random peptides\n",
    "for length in peptide_length:\n",
    "    with open(os.path.join(cleaved_human_proteome_dir, f'cleavable_peptides_length_{length}_no_duplicates.txt'), 'r') as f:\n",
    "        peptides = f.readlines()\n",
    "        peptides = [peptide.strip() for peptide in peptides]\n",
    "        random_peptides = np.random.choice(peptides, N_RND_PEPTIDES, replace=False)\n",
    "        \n",
    "    with open(os.path.join(processed_random_peptides_dir, f'random_peptides_length_{length}.txt'), 'w') as f:\n",
    "        for peptide in random_peptides:\n",
    "            f.write(f'{peptide}\\n')"
   ],
   "id": "362e34d415e57385",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f2dad0de65b208a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
